{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT NUSWhispers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69177b3210804bba81657dcec35c447b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5defea8dd13f42339f21fe991605db98",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_377e36ceea89488098101439cd7fe443",
              "IPY_MODEL_25c95c91c1d84dff802ce3390696eee1"
            ]
          }
        },
        "5defea8dd13f42339f21fe991605db98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "377e36ceea89488098101439cd7fe443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8972776a156940d2a8cc13f2a01a7caf",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a7067bd43e24bc7932750d7a44b3c5b"
          }
        },
        "25c95c91c1d84dff802ce3390696eee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71bc184a027746269e920f13cce079e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [25:28&lt;00:00, 305.64s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cc809bf6d354d58b2a514b2d35fefe2"
          }
        },
        "8972776a156940d2a8cc13f2a01a7caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a7067bd43e24bc7932750d7a44b3c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71bc184a027746269e920f13cce079e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cc809bf6d354d58b2a514b2d35fefe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42e8398111a041bca92deecaf310a6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd21a59947d8415daa123bccb7c9a690",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d420dd74b4f946778d32cc4e5b93756b",
              "IPY_MODEL_315a62d1288e4d05a4665be36be49d6e"
            ]
          }
        },
        "cd21a59947d8415daa123bccb7c9a690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d420dd74b4f946778d32cc4e5b93756b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5cc0380553a43fcad988f2d452f4926",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c757a37bd45429f9d9e68d9c64e94ed"
          }
        },
        "315a62d1288e4d05a4665be36be49d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39be4bfc593e4371a2b5d67a3766c436",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 22/? [00:01&lt;00:00, 14.29 tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_faa97fa206fb49d6a13405d9603fc2cd"
          }
        },
        "e5cc0380553a43fcad988f2d452f4926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c757a37bd45429f9d9e68d9c64e94ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39be4bfc593e4371a2b5d67a3766c436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "faa97fa206fb49d6a13405d9603fc2cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a9f8d30e9d24c048cabea03bc43826d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d0c05e73732465dbe93c184e97c7f99",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5285810949334e998d2c353356e84591",
              "IPY_MODEL_425851ff7ed845889176491dd06e5299"
            ]
          }
        },
        "0d0c05e73732465dbe93c184e97c7f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5285810949334e998d2c353356e84591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_18d472283f4a426889b9eb5417d5829b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_903cda2959ce4f78b09452cdc27e63ab"
          }
        },
        "425851ff7ed845889176491dd06e5299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bdf97b9602604694a38002d63aac1056",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:17&lt;00:00,  4.38s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0018aec64404723b365555933d4d87c"
          }
        },
        "18d472283f4a426889b9eb5417d5829b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "903cda2959ce4f78b09452cdc27e63ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdf97b9602604694a38002d63aac1056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0018aec64404723b365555933d4d87c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32b0deb027024c95bea8f4be5ebf81c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42b4336ee8354ef880fa907bd116bc14",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dfc419c7e57c4a5787f259bdf428b962",
              "IPY_MODEL_392c2971927745e4844de553b54c972d"
            ]
          }
        },
        "42b4336ee8354ef880fa907bd116bc14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfc419c7e57c4a5787f259bdf428b962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e02eacf2ab74e95aa0a4082bd71acd8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_953aded622674c5c9dfc9c0c4e6aeab9"
          }
        },
        "392c2971927745e4844de553b54c972d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f2b88817807145af81dcac32b63661f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:14&lt;00:00, 14.92s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e754a62e09f24f78a5c8ba5a7645efc3"
          }
        },
        "1e02eacf2ab74e95aa0a4082bd71acd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "953aded622674c5c9dfc9c0c4e6aeab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2b88817807145af81dcac32b63661f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e754a62e09f24f78a5c8ba5a7645efc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c845bd78fb674243b934a86c19747a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_545737ba2cbf42e082fa6828d1f51ce9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e29508b35c304443bb1daa9b27c6a45f",
              "IPY_MODEL_0be6057b0f244431a684a3afdefd8bd0"
            ]
          }
        },
        "545737ba2cbf42e082fa6828d1f51ce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e29508b35c304443bb1daa9b27c6a45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c253fbc338e74229aa37163354701387",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbf0e481650048be9cd8d688cd20340b"
          }
        },
        "0be6057b0f244431a684a3afdefd8bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a50fb00ee0194fe2a10a7f85208196f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  5.20ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ba3e0c082674f89a15b26b824c820d9"
          }
        },
        "c253fbc338e74229aa37163354701387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbf0e481650048be9cd8d688cd20340b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a50fb00ee0194fe2a10a7f85208196f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ba3e0c082674f89a15b26b824c820d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b45aeb67e7e4481b3b0c0da507bc0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8e48d07059e455a9843819d4f475c56",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_25f7b59f5a074718b830a8337595c9b6",
              "IPY_MODEL_34082f50a641461698058384154e8b9f"
            ]
          }
        },
        "e8e48d07059e455a9843819d4f475c56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25f7b59f5a074718b830a8337595c9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e63a8f7849b0435090452d2f61ed5c9f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ea034ec296b45d4acfb2e6ae7fb2130"
          }
        },
        "34082f50a641461698058384154e8b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d9accbe20f54075ba74c74425c92c96",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [1:25:18&lt;00:00, 1023.79s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d284d76934cb4d0f994f69a1e2d89522"
          }
        },
        "e63a8f7849b0435090452d2f61ed5c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ea034ec296b45d4acfb2e6ae7fb2130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d9accbe20f54075ba74c74425c92c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d284d76934cb4d0f994f69a1e2d89522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTQURfFmhxWD"
      },
      "source": [
        "# BERT NUSWhispers\n",
        "\n",
        "This notebook documents various explorations with regards to using BERT in the NUSWhispers sentiment analysis task. Note that it is in a pretty raw format and has not been tidied up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2W7oeQ4cQTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a9b912-9f9d-4835-d2e4-4c43541a1602"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHQSNW5j3jqo",
        "outputId": "11079e61-474a-4c2a-e33d-d020f96acae8"
      },
      "source": [
        "!git clone https://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@github.com/CindyTsai1/CS4248-Team23.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CS4248-Team23'...\n",
            "remote: Enumerating objects: 266, done.\u001b[K\n",
            "remote: Counting objects: 100% (266/266), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 266 (delta 132), reused 216 (delta 84), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (266/266), 45.50 MiB | 19.03 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n",
            "Checking out files: 100% (151/151), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79ZgBole5ZG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8576fded-2c8f-4061-a1fa-df91b15ad46b"
      },
      "source": [
        "!pip install datasets transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/43b396481a8298c6010afb93b3c1e71d4ba6f8c10797a7da8eb005e45081/datasets-1.5.0-py3-none-any.whl (192kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 8.3MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.2MB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/11/f7689b996f85e45f718745c899f6747ee5edb4878cadac0a41ab146828fa/fsspec-0.9.0-py3-none-any.whl (107kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 55.2MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 64.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 53.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=2e408d3ea693a288f4a5f8877e9509f43c9bff983ff26771ba2b264c7a927f41\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: fsspec, huggingface-hub, xxhash, datasets, tokenizers, sacremoses, transformers\n",
            "Successfully installed datasets-1.5.0 fsspec-0.9.0 huggingface-hub-0.0.8 sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-hSpyl55kcj",
        "outputId": "1627b35f-9787-411d-cc3e-c7f6b5cbfa6e"
      },
      "source": [
        "# check successful installation of transformers\n",
        "!python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-12 13:24:52.410243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Downloading: 100% 629/629 [00:00<00:00, 627kB/s]\n",
            "Downloading: 100% 268M/268M [00:03<00:00, 71.7MB/s]\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 921kB/s]\n",
            "Downloading: 100% 48.0/48.0 [00:00<00:00, 39.5kB/s]\n",
            "[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiUgC3ys3jGh"
      },
      "source": [
        "model_name = 'bert-base-cased'\n",
        "num_labels = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdueHywYpKuD"
      },
      "source": [
        "# 1. Extracting Contextual Embeddings of Pre-Trained BERT\n",
        "\n",
        "As we also have other non-textual features, we could extract the contextual embeddings of the NUSWhispers posts from the pre-trained BERT model. \n",
        "\n",
        "These embeddings (of size 768) can then be combined with the other features and fed into another classification model, e.g. Logistic Regression or a simple neural network (this is done in our repository's [main.py](https://github.com/CindyTsai1/CS4248-Team23/blob/main/main.py))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PVj7u27jIja"
      },
      "source": [
        "# Load pretrained model/tokenizer\n",
        "model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, \n",
        "                                                    transformers.BertTokenizer, \n",
        "                                                    'bert-base-cased')\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYiplVV6kQko"
      },
      "source": [
        "data_file = '/content/CS4248-Team23/data/v6_remove_punctuation_remove_non_english_correct_spelling_replace_short_form_slang.csv'\n",
        "df = pd.read_csv(data_file)\n",
        "\n",
        "def generate_embedding(x):\n",
        "  encoding = tokenizer.encode(x, truncation=True, padding=True, max_length=512)\n",
        "  input_ids = torch.tensor(encoding).unsqueeze(0)\n",
        "  with torch.no_grad():\n",
        "    output = model(input_ids)\n",
        "    last_hidden_state = output[0]\n",
        "  # Get [CLS] embedding\n",
        "  features = last_hidden_state[:,0,:].numpy()\n",
        "  return features\n",
        "\n",
        "embeddings = df['text'].apply(generate_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk29nKvI6T-j"
      },
      "source": [
        "embeddings.to_csv('drive/MyDrive/pt_bert_embeddings.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2erSh7UdZ3P"
      },
      "source": [
        "# 2. Finetuning BERT on NUSWhispers sentiment analysis task\n",
        "\n",
        "In the previous section, the pre-trained BERT model was simply used to evaluate and extract the embeddings from the NUSWhispers posts.\n",
        "\n",
        "In this section, we fine-tune the pre-trained BERT on the NUSWhispers post specifically for our text classification (sentiment analysis) task.\n",
        "\n",
        "References:\n",
        "- https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPlzfvfgEOk4"
      },
      "source": [
        "# load NUSWhispers dataset\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, load_metric\n",
        "\n",
        "data_file = '/content/CS4248-Team23/data/v6_remove_punctuation_remove_non_english_correct_spelling_replace_short_form_slang.csv'\n",
        "\n",
        "old_train = pd.read_csv(data_file)\n",
        "train = deepcopy(old_train)\n",
        "\n",
        "train_dataset, test_dataset = train_test_split(train, test_size=0.2, random_state=10)\n",
        "train_dataset, val_dataset = train_test_split(train, test_size=0.2, random_state=10)\n",
        "test_dataset, val_dataset = train_test_split(val_dataset, test_size=0.5, random_state=10)\n",
        "\n",
        "train_dataset_text = deepcopy(train_dataset[['text','label']])\n",
        "val_dataset_text = deepcopy(val_dataset[['text','label']])\n",
        "test_dataset_text = deepcopy(test_dataset[['text','label']])\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_dataset_text)\n",
        "val_dataset = Dataset.from_pandas(val_dataset_text)\n",
        "test_dataset = Dataset.from_pandas(test_dataset_text)\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
        "val_dataset = val_dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
        "\n",
        "columns_to_return = ['input_ids', 'label', 'attention_mask']\n",
        "train_dataset.set_format(type='torch', columns=columns_to_return)\n",
        "val_dataset.set_format(type='torch', columns=columns_to_return)\n",
        "test_dataset.set_format(type='torch', columns=columns_to_return)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4ccKy9xOcQQ",
        "outputId": "87dac8d8-cca5-4d1b-99c8-6e9a217fa3ad"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import GELU\n",
        "from transformers import BertModel, BertForSequenceClassification, BertForPreTraining,\\\n",
        "                         BertTokenizerFast, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def pt_bert(model_name, num_labels, train_mode=True):\n",
        "  model = BertForSequenceClassification.from_pretrained(model_name, \n",
        "                                                        num_labels=num_labels)\n",
        "  if train_mode:\n",
        "    model.train()\n",
        "  return model\n",
        "\n",
        "# def pt_bert_extended(model_name, num_labels, train_mode=True):\n",
        "#   class ExtendedBert(nn.Module):\n",
        "#       def __init__(self):\n",
        "#           super().__init__()\n",
        "\n",
        "#           self.bert = BertModel.from_pretrained(model_name)\n",
        "#           self.linear = nn.Linear(1024, 1024)\n",
        "#           self.act = GELU()\n",
        "#           self.classifier = nn.Linear(1024, num_labels)\n",
        "\n",
        "#       def forward(self, encoded, other_feats):\n",
        "#           # get the hidden state of the last layer\n",
        "#           last_hidden = self.bert(**encoded)[0]\n",
        "#           # concatenate with the other given features\n",
        "#           cat = torch.cat([last_hidden, other_feats], dim=-1)\n",
        "#           # pass through linear layer\n",
        "#           output = self.linear(cat)\n",
        "#           # pass through non-linear activation and final classifier layer\n",
        "#           return self.classifier(self.act(output))\n",
        "#   model = ExtendedBert()\n",
        "#   if train_mode:\n",
        "#     model.train()\n",
        "#   return model\n",
        "\n",
        "model = pt_bert(model_name, num_labels, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "sRcZZ5bt441X",
        "outputId": "e8a7a065-0cbb-4da2-ce46-d437c232a148"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./nuswhispersbert/results',          # output directory\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=4.0,            # total # of training epochs\n",
        "    per_device_train_batch_size=32,  # batch size per device during training\n",
        "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
        "    warmup_ratio=0.1,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./nuswhispersbert/logs',            # directory for storing logs\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        ")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='444' max='444' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [444/444 2:39:20, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=444, training_loss=1.1452488254856419, metrics={'train_runtime': 9585.6873, 'train_samples_per_second': 0.046, 'total_flos': 4691647640678400.0, 'epoch': 4.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 3247280128, 'train_mem_cpu_peaked_delta': 1634304})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "1UwgmggdMrxu",
        "outputId": "8060a06b-e8ba-4800-8cfa-d93efd14e9f9"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14/14 01:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 4.0,\n",
              " 'eval_accuracy': 0.5578231292517006,\n",
              " 'eval_f1': 0.4473423393402012,\n",
              " 'eval_loss': 1.1610209941864014,\n",
              " 'eval_mem_cpu_alloc_delta': -6082560,\n",
              " 'eval_mem_cpu_peaked_delta': 6082560,\n",
              " 'eval_precision': 0.5359161508989095,\n",
              " 'eval_recall': 0.44302641072377913,\n",
              " 'eval_runtime': 73.9135,\n",
              " 'eval_samples_per_second': 5.966}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9iNvvIjiFww"
      },
      "source": [
        "The fine-tuned BERT gave us a test f1-score of 0.417:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "_r3d5nI5jY25",
        "outputId": "d7541410-0e32-47c8-c38d-5a9901921b52"
      },
      "source": [
        "import json \n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "print(predictions.metrics)\n",
        "\n",
        "with open('results.json', 'w+') as f:\n",
        "  f.write(json.dumps(predictions.metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='28' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14/14 02:22]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'test_loss': 1.1826553344726562, 'test_accuracy': 0.5260770975056689, 'test_f1': 0.4172975243387377, 'test_precision': 0.47979861309014915, 'test_recall': 0.4160155344745687, 'test_runtime': 72.9537, 'test_samples_per_second': 6.045, 'test_mem_cpu_alloc_delta': -8663040, 'test_mem_cpu_peaked_delta': 9326592}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8CLeIXRX2nl"
      },
      "source": [
        "# save model\n",
        "save_directory = '/content/drive/MyDrive/nuswhispers_bert/'\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8lelEcX-k_l"
      },
      "source": [
        "# 2b. Extracting Contextual Embeddings of BERT finetuned on NUSWhispers\n",
        "\n",
        "In the previous section, we made use of the finetuning approach directly on NUSWhispers. However, we did not make use of the other non-textual features that we have. Hence, we could extract the contextual embeddings of the fine-tuned model, just like we did to the pre-trained model in the first section, and use that with other features (in main.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou4tBaNjx4jM"
      },
      "source": [
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "\n",
        "save_directory = '/content/drive/MyDrive/nuswhispers_bert/'\n",
        "tokenizer = BertTokenizerFast.from_pretrained(save_directory)\n",
        "model = BertForSequenceClassification.from_pretrained(save_directory,\n",
        "                                                      output_hidden_states=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJtc5UKb-hR9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "69177b3210804bba81657dcec35c447b",
            "5defea8dd13f42339f21fe991605db98",
            "377e36ceea89488098101439cd7fe443",
            "25c95c91c1d84dff802ce3390696eee1",
            "8972776a156940d2a8cc13f2a01a7caf",
            "9a7067bd43e24bc7932750d7a44b3c5b",
            "71bc184a027746269e920f13cce079e5",
            "3cc809bf6d354d58b2a514b2d35fefe2"
          ]
        },
        "id": "-Dn8U76O-ogY",
        "outputId": "9185d99f-49de-4da0-a509-4e82673b3909"
      },
      "source": [
        "# load NUSWhispers dataset\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, load_metric\n",
        "\n",
        "data_file = '/content/CS4248-Team23/data/v6_remove_punctuation_remove_non_english_correct_spelling_replace_short_form_slang.csv'\n",
        "\n",
        "old_train = pd.read_csv(data_file)\n",
        "train = deepcopy(old_train)\n",
        "\n",
        "train_dataset_text = deepcopy(train[['text','label']])\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_dataset_text)\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
        "\n",
        "columns_to_return = ['input_ids', 'label', 'attention_mask']\n",
        "train_dataset.set_format(type='torch', columns=columns_to_return)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69177b3210804bba81657dcec35c447b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqlC3SF_jA_F"
      },
      "source": [
        "Here we are extracting the embeddings produced by the final hidden layer (before the classification head), where we simply used the embeddings of each post's [CLS] token (a special token appended to the start of every text by the BERT tokenizer). There are also other strategies, e.g. average or max pooling all token's embeddings, taking the 2nd to last hidden layer's embeddings instead of the last, or even pooling the last 4 hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dfCIVBr-u5d"
      },
      "source": [
        "def generate_embedding(x):\n",
        "  inputs = {\n",
        "    \"input_ids\": torch.tensor(x['input_ids']).unsqueeze(0),\n",
        "    \"attention_mask\": torch.tensor(x['attention_mask']).unsqueeze(0),\n",
        "  }\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output = model(**inputs)\n",
        "    logits = output[0]\n",
        "    hidden_states = output[1]\n",
        "    last_hidden_state = hidden_states[1] # layer right before the classification head\n",
        "  # Get [CLS] embedding\n",
        "  features = last_hidden_state[:,0,:].numpy()\n",
        "\n",
        "  return features\n",
        "\n",
        "df = train_dataset.to_pandas()\n",
        "embeddings = df.apply(generate_embedding, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqViGDARDu6C"
      },
      "source": [
        "# sanity check\n",
        "# b = generate_embedding(df.iloc[0])\n",
        "# c = generate_embedding(df.iloc[100])\n",
        "# c[1][1][:,0,:] - b[1][1][:,0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lebm0Q5rOpb7",
        "outputId": "1e9b7e97-9851-44c3-b1fe-dd544c039749"
      },
      "source": [
        "embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [[0.3830672, -0.009595338, -0.04466594, 0.2164...\n",
              "1       [[0.31250125, -0.025139237, -0.07906971, 0.145...\n",
              "2       [[0.4044993, 0.11017956, -0.09175598, 0.163171...\n",
              "3       [[0.42715767, 0.12297561, -0.088395834, 0.1763...\n",
              "4       [[0.33505115, 0.028211728, -0.09869314, 0.1309...\n",
              "                              ...                        \n",
              "4402    [[0.35374606, 0.05952185, -0.110185266, 0.1314...\n",
              "4403    [[0.42239362, 0.0930569, -0.07726694, 0.185199...\n",
              "4404    [[0.3414257, 0.00013566887, -0.057890713, 0.18...\n",
              "4405    [[0.37562442, 0.0037782686, -0.104104154, 0.18...\n",
              "4406    [[0.36251536, 0.009120925, -0.013022443, 0.200...\n",
              "Length: 4407, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtcV4zhY3hNs"
      },
      "source": [
        "embeddings.to_csv('drive/MyDrive/nw_bert_embeddings.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVUC1sivPTxK"
      },
      "source": [
        "# 3. Further Pre-Training BERT on GoEmotion\n",
        "\n",
        "In this section, we explore the idea of further pre-training the original pre-trained BERT model. As the original model was pre-trained on English Wikipedia and BooksCorpus, it might not have been able to capture the distributional statistics of our target domain, i.e. social media (Facebook posts), which tend to have more informal language.\n",
        "\n",
        "Hence, we could further pre-train using the goemotions dataset which contains a pretty large (200k examples) set of Reddit posts, on the masked language modelling task.\n",
        "\n",
        "We hypothesize that by tuning the language model to better fit the target domain, the performance of the downstream task (sentiment analysis on NUSWhispers) could be improved.\n",
        "\n",
        "Refererences: \n",
        "- https://github.com/huggingface/transformers/tree/master/examples: \n",
        "- https://huggingface.co/blog/pytorch-xla"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs0e7alhQJfM"
      },
      "source": [
        "To speed up the pre-training process, please change the colab's runtime to make use of TPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMhrceLyVocr",
        "outputId": "e40ca73a-c481-4832-f26f-483298a6fad7"
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "\n",
        "!pip install -U git+https://github.com/huggingface/transformers\n",
        "\n",
        "!pip install datasets\n",
        "\n",
        "# Install Colab TPU compatible PyTorch/TPU wheels and dependencies\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-agt3w64v\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-agt3w64v\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (0.0.44)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.8.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0.dev0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2.10)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.6.0.dev0-cp37-none-any.whl size=2090005 sha256=9edf51e6b43ac951e22d519800bde168860f3ac1e7391c8a362122330e2a3f60\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o4rvvnlc/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 4.5.0\n",
            "    Uninstalling transformers-4.5.0:\n",
            "      Successfully uninstalled transformers-4.5.0\n",
            "Successfully installed transformers-4.6.0.dev0\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Collecting cloud-tpu-client==0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting torch-xla==1.8\n",
            "\u001b[?25l  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl (144.6MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144.6MB 49kB/s \n",
            "\u001b[?25hCollecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.28.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (54.2.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "\u001b[31mERROR: earthengine-api 0.1.258 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client, torch-xla\n",
            "  Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 torch-xla-1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HN5kXJpPnUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff02a74-b1d9-45c1-945b-1695e224b139"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_mlm.py\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/xla_spawn.py\n",
        "!wget -P goemotions_data/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv\n",
        "!wget -P goemotions_data/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv\n",
        "!wget -P goemotions_data/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-12 05:20:21--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_mlm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20875 (20K) [text/plain]\n",
            "Saving to: â€˜run_mlm.pyâ€™\n",
            "\n",
            "\rrun_mlm.py            0%[                    ]       0  --.-KB/s               \rrun_mlm.py          100%[===================>]  20.39K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-04-12 05:20:21 (16.6 MB/s) - â€˜run_mlm.pyâ€™ saved [20875/20875]\n",
            "\n",
            "--2021-04-12 05:20:21--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/xla_spawn.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2519 (2.5K) [text/plain]\n",
            "Saving to: â€˜xla_spawn.pyâ€™\n",
            "\n",
            "xla_spawn.py        100%[===================>]   2.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-12 05:20:22 (51.5 MB/s) - â€˜xla_spawn.pyâ€™ saved [2519/2519]\n",
            "\n",
            "--2021-04-12 05:20:22--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.121.128, 108.177.120.128, 142.251.6.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.121.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14174600 (14M) [application/octet-stream]\n",
            "Saving to: â€˜goemotions_data/goemotions_1.csvâ€™\n",
            "\n",
            "goemotions_1.csv    100%[===================>]  13.52M  85.9MB/s    in 0.2s    \n",
            "\n",
            "2021-04-12 05:20:22 (85.9 MB/s) - â€˜goemotions_data/goemotions_1.csvâ€™ saved [14174600/14174600]\n",
            "\n",
            "--2021-04-12 05:20:22--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.121.128, 108.177.120.128, 142.251.6.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.121.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14173154 (14M) [application/octet-stream]\n",
            "Saving to: â€˜goemotions_data/goemotions_2.csvâ€™\n",
            "\n",
            "goemotions_2.csv    100%[===================>]  13.52M  72.3MB/s    in 0.2s    \n",
            "\n",
            "2021-04-12 05:20:22 (72.3 MB/s) - â€˜goemotions_data/goemotions_2.csvâ€™ saved [14173154/14173154]\n",
            "\n",
            "--2021-04-12 05:20:23--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.70.128, 64.233.191.128, 209.85.145.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.70.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14395164 (14M) [application/octet-stream]\n",
            "Saving to: â€˜goemotions_data/goemotions_3.csvâ€™\n",
            "\n",
            "goemotions_3.csv    100%[===================>]  13.73M  74.4MB/s    in 0.2s    \n",
            "\n",
            "2021-04-12 05:20:23 (74.4 MB/s) - â€˜goemotions_data/goemotions_3.csvâ€™ saved [14395164/14395164]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91,
          "referenced_widgets": [
            "42e8398111a041bca92deecaf310a6da",
            "cd21a59947d8415daa123bccb7c9a690",
            "d420dd74b4f946778d32cc4e5b93756b",
            "315a62d1288e4d05a4665be36be49d6e",
            "e5cc0380553a43fcad988f2d452f4926",
            "3c757a37bd45429f9d9e68d9c64e94ed",
            "39be4bfc593e4371a2b5d67a3766c436",
            "faa97fa206fb49d6a13405d9603fc2cd"
          ]
        },
        "id": "yz0g2HjaQKsw",
        "outputId": "ffe2a15c-621f-4bbc-94d7-572c551acc30"
      },
      "source": [
        "# from transformers import BertTokenizerFast\n",
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset('csv', data_files=[\n",
        "                                     'goemotions_data/goemotions_1.csv',\n",
        "                                     'goemotions_data/goemotions_2.csv',\n",
        "                                     'goemotions_data/goemotions_3.csv'])\n",
        "with open('goemotions_corpus.txt','w+') as f:\n",
        "  corpus='\\n'.join(train_dataset['train']['text'])\n",
        "  f.write(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-4a82ec2353cca12b\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-4a82ec2353cca12b/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42e8398111a041bca92deecaf310a6da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-4a82ec2353cca12b/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgShn2XMbmF8",
        "outputId": "38cacdbe-f08d-4ca6-9c50-672f68989644"
      },
      "source": [
        "# set up TPU\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Note that the `tpu` argument is for Colab-only\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "# strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.75.235.170:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.75.235.170:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfvEPVHhTEg5",
        "outputId": "e4d5c743-a0d3-4fcc-d24a-c8b52a00d8d6"
      },
      "source": [
        "!export TPU_IP_ADDRESS=\"10.75.235.170\"  # ex. 10.0.0.2\n",
        "!export XRT_TPU_CONFIG=\"tpu_worker;0;$TPU_IP_ADDRESS:8470\"\n",
        "\n",
        "# !python run_mlm.py \\\n",
        "#     --model_name_or_path bert-base-cased \\\n",
        "#     --train_file goemotions_corpus.txt \\\n",
        "#     --do_train \\\n",
        "#     --line_by_line \\\n",
        "#     --output_dir goemo-mlm\n",
        "\n",
        "!python xla_spawn.py \\\n",
        "  run_mlm.py \\\n",
        "  --model_name_or_path bert-base-cased \\\n",
        "  --train_file goemotions_corpus.txt \\\n",
        "  --do_train \\\n",
        "  --line_by_line \\\n",
        "  --pad_to_max_length \\\n",
        "  --output_dir /content/drive/MyDrive/goemo-mlm \\\n",
        "  --cache_dir cache_dir \\\n",
        "  --overwrite_cache \\\n",
        "  --tpu_metrics_debug \\\n",
        "  --save_steps 20000\n",
        "  # --overwrite_output_dir \\\n",
        "  # --num_train_epochs 3 \\\n",
        "  # --per_device_train_batch_size 8 \\\n",
        "  # --per_device_eval_batch_size 8 \\\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.8\n",
            "WARNING:run_mlm:Process rank: -1, device: xla:1, n_gpu: 0distributed training: False, 16-bits training: False\n",
            "INFO:run_mlm:Training/evaluation parameters TrainingArguments(output_dir=/content/drive/MyDrive/goemo-mlm, overwrite_output_dir=False, do_train=True, do_eval=None, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/Apr12_05-21-51_f9bc37ee942f, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=20000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=1, tpu_metrics_debug=True, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/content/drive/MyDrive/goemo-mlm, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=0, mp_parameters=)\n",
            "WARNING:datasets.builder:Using custom data configuration default-34118653f1cfaef2\n",
            "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-34118653f1cfaef2/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-34118653f1cfaef2/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n",
            "[INFO|file_utils.py:1394] 2021-04-12 05:22:07,778 >> https://huggingface.co/bert-base-cased/resolve/main/config.json not found in cache or force_download set to True, downloading to /content/cache_dir/tmpip460s6n\n",
            "Downloading: 100% 433/433 [00:00<00:00, 327kB/s]\n",
            "[INFO|file_utils.py:1398] 2021-04-12 05:22:07,879 >> storing https://huggingface.co/bert-base-cased/resolve/main/config.json in cache at cache_dir/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.0d87139f53a477d9f900f8a9020c367863079014bdaf2aa713f4b64cf1782655\n",
            "[INFO|file_utils.py:1401] 2021-04-12 05:22:07,880 >> creating metadata file for cache_dir/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.0d87139f53a477d9f900f8a9020c367863079014bdaf2aa713f4b64cf1782655\n",
            "[INFO|configuration_utils.py:490] 2021-04-12 05:22:07,880 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at cache_dir/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.0d87139f53a477d9f900f8a9020c367863079014bdaf2aa713f4b64cf1782655\n",
            "[INFO|configuration_utils.py:526] 2021-04-12 05:22:07,881 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.6.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:490] 2021-04-12 05:22:07,983 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at cache_dir/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.0d87139f53a477d9f900f8a9020c367863079014bdaf2aa713f4b64cf1782655\n",
            "[INFO|configuration_utils.py:526] 2021-04-12 05:22:07,984 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.6.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1394] 2021-04-12 05:22:08,090 >> https://huggingface.co/bert-base-cased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /content/cache_dir/tmpragcna0n\n",
            "Downloading: 100% 213k/213k [00:00<00:00, 1.86MB/s]\n",
            "[INFO|file_utils.py:1398] 2021-04-12 05:22:08,309 >> storing https://huggingface.co/bert-base-cased/resolve/main/vocab.txt in cache at cache_dir/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
            "[INFO|file_utils.py:1401] 2021-04-12 05:22:08,310 >> creating metadata file for cache_dir/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
            "[INFO|file_utils.py:1394] 2021-04-12 05:22:08,417 >> https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /content/cache_dir/tmpxe_59y38\n",
            "Downloading: 100% 436k/436k [00:00<00:00, 3.62MB/s]\n",
            "[INFO|file_utils.py:1398] 2021-04-12 05:22:08,643 >> storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json in cache at cache_dir/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
            "[INFO|file_utils.py:1401] 2021-04-12 05:22:08,643 >> creating metadata file for cache_dir/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
            "[INFO|file_utils.py:1394] 2021-04-12 05:22:08,952 >> https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /content/cache_dir/tmpg2k4tvc8\n",
            "Downloading: 100% 29.0/29.0 [00:00<00:00, 22.0kB/s]\n",
            "[INFO|file_utils.py:1398] 2021-04-12 05:22:09,054 >> storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json in cache at cache_dir/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "[INFO|file_utils.py:1401] 2021-04-12 05:22:09,054 >> creating metadata file for cache_dir/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "[INFO|tokenization_utils_base.py:1713] 2021-04-12 05:22:09,055 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at cache_dir/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
            "[INFO|tokenization_utils_base.py:1713] 2021-04-12 05:22:09,055 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at cache_dir/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
            "[INFO|tokenization_utils_base.py:1713] 2021-04-12 05:22:09,055 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1713] 2021-04-12 05:22:09,055 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1713] 2021-04-12 05:22:09,055 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at cache_dir/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "[INFO|file_utils.py:1394] 2021-04-12 05:22:09,183 >> https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /content/cache_dir/tmp7jn4xj5f\n",
            "Downloading: 100% 436M/436M [00:06<00:00, 65.0MB/s]\n",
            "[INFO|file_utils.py:1398] 2021-04-12 05:22:16,085 >> storing https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin in cache at cache_dir/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
            "[INFO|file_utils.py:1401] 2021-04-12 05:22:16,085 >> creating metadata file for cache_dir/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
            "[INFO|modeling_utils.py:1069] 2021-04-12 05:22:16,086 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at cache_dir/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
            "[WARNING|modeling_utils.py:1190] 2021-04-12 05:22:20,338 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[INFO|modeling_utils.py:1207] 2021-04-12 05:22:20,339 >> All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
            "100% 212/212 [00:30<00:00,  6.99ba/s]\n",
            "[INFO|trainer.py:489] 2021-04-12 05:22:56,775 >> The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask.\n",
            "[INFO|trainer.py:919] 2021-04-12 05:22:57,007 >> Loading model from /content/drive/MyDrive/goemo-mlm/checkpoint-20000).\n",
            "[INFO|configuration_utils.py:488] 2021-04-12 05:22:57,253 >> loading configuration file /content/drive/MyDrive/goemo-mlm/checkpoint-20000/config.json\n",
            "[INFO|configuration_utils.py:526] 2021-04-12 05:22:57,254 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.6.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:1067] 2021-04-12 05:22:57,255 >> loading weights file /content/drive/MyDrive/goemo-mlm/checkpoint-20000/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1198] 2021-04-12 05:23:06,610 >> All model checkpoint weights were used when initializing BertForMaskedLM.\n",
            "\n",
            "[INFO|modeling_utils.py:1207] 2021-04-12 05:23:06,610 >> All the weights of BertForMaskedLM were initialized from the model checkpoint at /content/drive/MyDrive/goemo-mlm/checkpoint-20000.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
            "[INFO|trainer.py:1011] 2021-04-12 05:23:54,937 >> ***** Running training *****\n",
            "[INFO|trainer.py:1012] 2021-04-12 05:23:54,937 >>   Num examples = 211225\n",
            "[INFO|trainer.py:1013] 2021-04-12 05:23:54,937 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1014] 2021-04-12 05:23:54,937 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1015] 2021-04-12 05:23:54,938 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:1016] 2021-04-12 05:23:54,938 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1017] 2021-04-12 05:23:54,938 >>   Total optimization steps = 79212\n",
            "[INFO|trainer.py:1036] 2021-04-12 05:23:55,063 >>   Continuing training from checkpoint, will skip to saved global_step\n",
            "[INFO|trainer.py:1037] 2021-04-12 05:23:55,063 >>   Continuing training from epoch 0\n",
            "[INFO|trainer.py:1038] 2021-04-12 05:23:55,063 >>   Continuing training from global step 20000\n",
            "[INFO|trainer.py:1041] 2021-04-12 05:23:55,064 >>   Will skip the first 0 epochs then the first 20000 batches in the first epoch.\n",
            "{'loss': 2.7026, 'learning_rate': 3.70600414078675e-05, 'epoch': 0.78}\n",
            "{'loss': 2.7241, 'learning_rate': 3.674443266171793e-05, 'epoch': 0.8}\n",
            "{'loss': 2.7233, 'learning_rate': 3.642882391556835e-05, 'epoch': 0.81}\n",
            "{'loss': 2.6429, 'learning_rate': 3.611321516941878e-05, 'epoch': 0.83}\n",
            "{'loss': 2.6155, 'learning_rate': 3.57976064232692e-05, 'epoch': 0.85}\n",
            "{'loss': 2.6065, 'learning_rate': 3.548199767711963e-05, 'epoch': 0.87}\n",
            "{'loss': 2.5902, 'learning_rate': 3.516638893097006e-05, 'epoch': 0.89}\n",
            "{'loss': 2.6739, 'learning_rate': 3.485078018482048e-05, 'epoch': 0.91}\n",
            "{'loss': 2.6223, 'learning_rate': 3.453517143867091e-05, 'epoch': 0.93}\n",
            "{'loss': 2.5647, 'learning_rate': 3.4219562692521333e-05, 'epoch': 0.95}\n",
            "{'loss': 2.5921, 'learning_rate': 3.390395394637176e-05, 'epoch': 0.97}\n",
            "{'loss': 2.6124, 'learning_rate': 3.3588345200222185e-05, 'epoch': 0.98}\n",
            " 33% 26404/79212 [43:09<5:04:14,  2.89it/s]Metric: CompileTime\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 02m57s010ms719.678us\n",
            "  ValueRate: 045ms879.755us / second\n",
            "  Rate: 0.00230133 / second\n",
            "  Percentiles: 1%=03s237ms464.652us; 5%=03s237ms464.652us; 10%=03s237ms464.652us; 20%=11s266ms557.661us; 50%=26s001ms585.078us; 80%=28s577ms125.419us; 90%=28s709ms447.415us; 95%=28s709ms447.415us; 99%=28s709ms447.415us\n",
            "Metric: DeviceLockWait\n",
            "  TotalSamples: 26418\n",
            "  Accumulator: 204ms884.493us\n",
            "  ValueRate: 318.695us / second\n",
            "  Rate: 2.62509 / second\n",
            "  Percentiles: 1%=003.162us; 5%=003.284us; 10%=003.362us; 20%=003.489us; 50%=003.778us; 80%=004.100us; 90%=004.399us; 95%=004.679us; 99%=005.504us\n",
            "Metric: ExecuteTime\n",
            "  TotalSamples: 6417\n",
            "  Accumulator: 30m44s090ms617.777us\n",
            "  ValueRate: 730ms604.786us / second\n",
            "  Rate: 2.62426 / second\n",
            "  Percentiles: 1%=276ms498.847us; 5%=277ms980.581us; 10%=277ms298.108us; 20%=278ms750.629us; 50%=279ms679.749us; 80%=279ms236.394us; 90%=280ms514.978us; 95%=280ms710.153us; 99%=280ms103.110us\n",
            "Metric: InboundData\n",
            "  TotalSamples: 12\n",
            "  Accumulator: 48.00B\n",
            "  ValueRate: 0.02B / second\n",
            "  Rate: 0.00593888 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=4.00B; 80%=4.00B; 90%=4.00B; 95%=4.00B; 99%=4.00B\n",
            "Metric: InputOutputAliasCount\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 4070.00\n",
            "  ValueRate: 1.57 / second\n",
            "  Rate: 0.00231733 / second\n",
            "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=813.00; 50%=813.00; 80%=813.00; 90%=817.00; 95%=817.00; 99%=817.00\n",
            "Metric: IrValueTensorToXlaData\n",
            "  TotalSamples: 816\n",
            "  Accumulator: 23s461ms870.425us\n",
            "  ValueRate: 373ms499.055us / second\n",
            "  Rate: 12.9908 / second\n",
            "  Percentiles: 1%=941.273us; 5%=001ms061.167us; 10%=001ms224.279us; 20%=002ms546.383us; 50%=002ms957.281us; 80%=028ms434.653us; 90%=097ms159.723us; 95%=100ms777.049us; 99%=104ms508.279us\n",
            "Metric: OutboundData\n",
            "  TotalSamples: 20238\n",
            "  Accumulator: 6.14GB\n",
            "  ValueRate: 348.17KB / second\n",
            "  Rate: 6.22894 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=8.00B; 80%=8.00B; 90%=512.00KB; 95%=512.00KB; 99%=512.00KB\n",
            "Metric: ReleaseDataHandlesTime\n",
            "  TotalSamples: 75208\n",
            "  Accumulator: 02m02s144ms072.052us\n",
            "  ValueRate: 030ms181.440us / second\n",
            "  Rate: 17.7308 / second\n",
            "  Percentiles: 1%=893.857us; 5%=001ms043.701us; 10%=001ms122.015us; 20%=001ms232.756us; 50%=002ms696.107us; 80%=002ms067.354us; 90%=002ms312.522us; 95%=002ms491.779us; 99%=003ms134.873us\n",
            "Metric: TensorsGraphSize\n",
            "  TotalSamples: 6417\n",
            "  Accumulator: 73574848.00\n",
            "  ValueRate: 30077.75 / second\n",
            "  Rate: 2.6232 / second\n",
            "  Percentiles: 1%=11484.00; 5%=11484.00; 10%=11484.00; 20%=11484.00; 50%=11484.00; 80%=11484.00; 90%=11484.00; 95%=11484.00; 99%=11484.00\n",
            "Metric: TransferFromServerTime\n",
            "  TotalSamples: 12\n",
            "  Accumulator: 047ms004.280us\n",
            "  ValueRate: 023.263us / second\n",
            "  Rate: 0.00593888 / second\n",
            "  Percentiles: 1%=002ms032.793us; 5%=002ms032.793us; 10%=002ms087.662us; 20%=002ms164.083us; 50%=005ms031.369us; 80%=006ms660.552us; 90%=006ms070.566us; 95%=006ms210.757us; 99%=006ms210.757us\n",
            "Metric: TransferToServerTime\n",
            "  TotalSamples: 20238\n",
            "  Accumulator: 33m59s533ms440.248us\n",
            "  ValueRate: 811ms042.632us / second\n",
            "  Rate: 6.22354 / second\n",
            "  Percentiles: 1%=002ms737.128us; 5%=002ms920.511us; 10%=002ms026.892us; 20%=002ms163.063us; 50%=208ms810.552us; 80%=263ms211.586us; 90%=272ms117.312us; 95%=273ms122.372us; 99%=274ms815.499us\n",
            "Metric: TransferToServerTransformTime\n",
            "  TotalSamples: 20238\n",
            "  Accumulator: 09s582ms457.890us\n",
            "  ValueRate: 002ms607.426us / second\n",
            "  Rate: 6.22894 / second\n",
            "  Percentiles: 1%=109.059us; 5%=125.461us; 10%=133.658us; 20%=145.918us; 50%=178.978us; 80%=229.410us; 90%=710.661us; 95%=900.140us; 99%=001ms103.123us\n",
            "Counter: CachedCompile\n",
            "  Value: 6411\n",
            "Counter: CreateCompileHandles\n",
            "  Value: 6\n",
            "Counter: CreateDataHandles\n",
            "  Value: 5326939\n",
            "Counter: CreateXlaTensor\n",
            "  Value: 22028547\n",
            "Counter: DestroyDataHandles\n",
            "  Value: 5325107\n",
            "Counter: DestroyXlaTensor\n",
            "  Value: 22027523\n",
            "Counter: DeviceDataCacheMiss\n",
            "  Value: 6416\n",
            "Counter: MarkStep\n",
            "  Value: 26406\n",
            "Counter: ReleaseDataHandles\n",
            "  Value: 5325787\n",
            "Counter: UncachedCompile\n",
            "  Value: 6\n",
            "Counter: XRTAllocateFromTensor_Empty\n",
            "  Value: 446\n",
            "Counter: XrtCompile_Empty\n",
            "  Value: 128\n",
            "Counter: XrtExecuteChained_Empty\n",
            "  Value: 128\n",
            "Counter: XrtExecute_Empty\n",
            "  Value: 128\n",
            "Counter: XrtMemoryInfo_Empty\n",
            "  Value: 128\n",
            "Counter: XrtRead_Empty\n",
            "  Value: 128\n",
            "Counter: XrtReleaseAllocationHandle_Empty\n",
            "  Value: 128\n",
            "Counter: XrtReleaseCompileHandle_Empty\n",
            "  Value: 128\n",
            "Counter: XrtSessionCount\n",
            "  Value: 10\n",
            "Counter: XrtSubTuple_Empty\n",
            "  Value: 128\n",
            "Counter: aten::_local_scalar_dense\n",
            "  Value: 12\n",
            "Counter: xla::_copy_from\n",
            "  Value: 20029\n",
            "Counter: xla::_log_softmax\n",
            "  Value: 6404\n",
            "Counter: xla::_log_softmax_backward_data\n",
            "  Value: 6404\n",
            "Counter: xla::_s_where\n",
            "  Value: 6404\n",
            "Counter: xla::_softmax\n",
            "  Value: 76848\n",
            "Counter: xla::_softmax_backward_data\n",
            "  Value: 76848\n",
            "Counter: xla::_unsafe_view\n",
            "  Value: 627592\n",
            "Counter: xla::add\n",
            "  Value: 550744\n",
            "Counter: xla::add_\n",
            "  Value: 4386537\n",
            "Counter: xla::addcdiv_\n",
            "  Value: 1300012\n",
            "Counter: xla::addcmul\n",
            "  Value: 166504\n",
            "Counter: xla::addcmul_\n",
            "  Value: 1300012\n",
            "Counter: xla::as_strided\n",
            "  Value: 13625\n",
            "Counter: xla::bernoulli_\n",
            "  Value: 236948\n",
            "Counter: xla::bmm\n",
            "  Value: 461088\n",
            "Counter: xla::div\n",
            "  Value: 160100\n",
            "Counter: xla::div_\n",
            "  Value: 236948\n",
            "Counter: xla::embedding\n",
            "  Value: 19212\n",
            "Counter: xla::embedding_dense_backward\n",
            "  Value: 19212\n",
            "Counter: xla::empty\n",
            "  Value: 263381\n",
            "Counter: xla::empty_strided\n",
            "  Value: 13625\n",
            "Counter: xla::expand\n",
            "  Value: 307392\n",
            "Counter: xla::fill_\n",
            "  Value: 6404\n",
            "Counter: xla::gelu\n",
            "  Value: 83252\n",
            "Counter: xla::gelu_backward\n",
            "  Value: 83252\n",
            "Counter: xla::index_select\n",
            "  Value: 19212\n",
            "Counter: xla::lt\n",
            "  Value: 6404\n",
            "Counter: xla::mm\n",
            "  Value: 1421688\n",
            "Counter: xla::mul\n",
            "  Value: 1146316\n",
            "Counter: xla::mul_\n",
            "  Value: 3900036\n",
            "Counter: xla::native_batch_norm\n",
            "  Value: 166504\n",
            "Counter: xla::native_batch_norm_backward\n",
            "  Value: 166504\n",
            "Counter: xla::nll_loss_backward\n",
            "  Value: 6404\n",
            "Counter: xla::nll_loss_forward\n",
            "  Value: 6404\n",
            "Counter: xla::norm\n",
            "  Value: 1306416\n",
            "Counter: xla::permute\n",
            "  Value: 614784\n",
            "Counter: xla::rsub\n",
            "  Value: 6404\n",
            "Counter: xla::slice\n",
            "  Value: 19212\n",
            "Counter: xla::sqrt\n",
            "  Value: 1300012\n",
            "Counter: xla::stack\n",
            "  Value: 6404\n",
            "Counter: xla::sub_\n",
            "  Value: 12\n",
            "Counter: xla::sum\n",
            "  Value: 813307\n",
            "Counter: xla::t\n",
            "  Value: 1895584\n",
            "Counter: xla::transpose\n",
            "  Value: 461088\n",
            "Counter: xla::unsqueeze\n",
            "  Value: 12808\n",
            "Counter: xla::view\n",
            "  Value: 5296108\n",
            "Counter: xla::zero_\n",
            "  Value: 1300012\n",
            "Metric: XrtAllocateFromTensor\n",
            "  TotalSamples: 119658\n",
            "  Accumulator: 03m15s017ms121.239us\n",
            "  Mean: 001ms128.206us\n",
            "  StdDev: 526.406us\n",
            "  Rate: 16.2431 / second\n",
            "  Percentiles: 25%=625.863us; 50%=001ms143.576us; 80%=002ms607.995us; 90%=002ms803.599us; 95%=002ms972.660us; 99%=002ms371.957us\n",
            "Metric: XrtCompile\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 02m57s659ms349.400us\n",
            "  Mean: 19s443ms224.900us\n",
            "  StdDev: 09s200ms886.723us\n",
            "  Rate: 0.00230129 / second\n",
            "  Percentiles: 25%=11s241ms668.931us; 50%=26s927ms110.922us; 80%=28s501ms011.701us; 90%=28s635ms667.540us; 95%=28s635ms667.540us; 99%=28s635ms667.540us\n",
            "Metric: XrtExecute\n",
            "  TotalSamples: 6417\n",
            "  Accumulator: 29m26s372ms732.143us\n",
            "  Mean: 275ms242.657us\n",
            "  StdDev: 009ms480.708us\n",
            "  Rate: 2.62421 / second\n",
            "  Percentiles: 25%=275ms187.733us; 50%=276ms907.531us; 80%=276ms419.546us; 90%=277ms674.211us; 95%=277ms862.755us; 99%=277ms137.529us\n",
            "Metric: XrtExecutorEvict\n",
            "  TotalSamples: 0\n",
            "  Accumulator: nanB\n",
            "  Mean: nanB\n",
            "  StdDev: nanB\n",
            "  Percentiles: \n",
            "Metric: XrtReadLiteral\n",
            "  TotalSamples: 12\n",
            "  Accumulator: 010ms543.533us\n",
            "  Mean: 795.294us\n",
            "  StdDev: 120.767us\n",
            "  Rate: 0.00593865 / second\n",
            "  Percentiles: 25%=710.402us; 50%=809.732us; 80%=923.652us; 90%=945.248us; 95%=946.972us; 99%=946.972us\n",
            "Metric: XrtReleaseAllocation\n",
            "  TotalSamples: 75213\n",
            "  Accumulator: 42s140ms012.297us\n",
            "  Mean: 637.429us\n",
            "  StdDev: 464.182us\n",
            "  Rate: 17.7302 / second\n",
            "  Percentiles: 25%=193.716us; 50%=624.529us; 80%=001ms011.152us; 90%=001ms237.576us; 95%=001ms394.592us; 99%=002ms998.935us\n",
            "\n",
            "{'loss': 2.5821, 'learning_rate': 3.3272736454072614e-05, 'epoch': 1.0}\n",
            "{'loss': 2.4946, 'learning_rate': 3.295712770792304e-05, 'epoch': 1.02}\n",
            "{'loss': 2.6307, 'learning_rate': 3.264151896177347e-05, 'epoch': 1.04}\n",
            "{'loss': 2.6147, 'learning_rate': 3.2325910215623894e-05, 'epoch': 1.06}\n",
            "{'loss': 2.5956, 'learning_rate': 3.201030146947432e-05, 'epoch': 1.08}\n",
            "{'loss': 2.5528, 'learning_rate': 3.1694692723324746e-05, 'epoch': 1.1}\n",
            "{'loss': 2.57, 'learning_rate': 3.1379083977175175e-05, 'epoch': 1.12}\n",
            "{'loss': 2.5644, 'learning_rate': 3.1063475231025604e-05, 'epoch': 1.14}\n",
            "{'loss': 2.531, 'learning_rate': 3.074786648487603e-05, 'epoch': 1.16}\n",
            "{'loss': 2.5425, 'learning_rate': 3.0432257738726455e-05, 'epoch': 1.17}\n",
            "{'loss': 2.5337, 'learning_rate': 3.0116648992576884e-05, 'epoch': 1.19}\n",
            "{'loss': 2.5512, 'learning_rate': 2.980104024642731e-05, 'epoch': 1.21}\n",
            "{'loss': 2.4595, 'learning_rate': 2.948543150027774e-05, 'epoch': 1.23}\n",
            "{'loss': 2.4957, 'learning_rate': 2.916982275412816e-05, 'epoch': 1.25}\n",
            "{'loss': 2.5123, 'learning_rate': 2.885421400797859e-05, 'epoch': 1.27}\n",
            "{'loss': 2.5166, 'learning_rate': 2.8538605261829016e-05, 'epoch': 1.29}\n",
            "{'loss': 2.485, 'learning_rate': 2.8222996515679445e-05, 'epoch': 1.31}\n",
            "{'loss': 2.5746, 'learning_rate': 2.790738776952987e-05, 'epoch': 1.33}\n",
            "{'loss': 2.486, 'learning_rate': 2.75917790233803e-05, 'epoch': 1.34}\n",
            "{'loss': 2.5163, 'learning_rate': 2.7276170277230722e-05, 'epoch': 1.36}\n",
            "{'loss': 2.4646, 'learning_rate': 2.696056153108115e-05, 'epoch': 1.38}\n",
            "{'loss': 2.4732, 'learning_rate': 2.6644952784931577e-05, 'epoch': 1.4}\n",
            "{'loss': 2.5119, 'learning_rate': 2.6329344038782006e-05, 'epoch': 1.42}\n",
            "{'loss': 2.4348, 'learning_rate': 2.6013735292632428e-05, 'epoch': 1.44}\n",
            "{'loss': 2.4608, 'learning_rate': 2.569812654648286e-05, 'epoch': 1.46}\n",
            "{'loss': 2.4584, 'learning_rate': 2.5382517800333283e-05, 'epoch': 1.48}\n",
            "{'loss': 2.5146, 'learning_rate': 2.5066909054183712e-05, 'epoch': 1.5}\n",
            "{'loss': 2.5097, 'learning_rate': 2.4751300308034137e-05, 'epoch': 1.51}\n",
            " 50% 40000/79212 [2:05:35<4:01:24,  2.71it/s][INFO|trainer.py:1637] 2021-04-12 07:29:30,188 >> Saving model checkpoint to /content/drive/MyDrive/goemo-mlm/checkpoint-40000\n",
            "[INFO|configuration_utils.py:329] 2021-04-12 07:29:30,204 >> Configuration saved in /content/drive/MyDrive/goemo-mlm/checkpoint-40000/config.json\n",
            "[INFO|modeling_utils.py:848] 2021-04-12 07:30:02,037 >> Model weights saved in /content/drive/MyDrive/goemo-mlm/checkpoint-40000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1907] 2021-04-12 07:30:02,044 >> tokenizer config file saved in /content/drive/MyDrive/goemo-mlm/checkpoint-40000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1913] 2021-04-12 07:30:02,048 >> Special tokens file saved in /content/drive/MyDrive/goemo-mlm/checkpoint-40000/special_tokens_map.json\n",
            "{'loss': 2.4695, 'learning_rate': 2.4435691561884563e-05, 'epoch': 1.53}\n",
            "{'loss': 2.4892, 'learning_rate': 2.412008281573499e-05, 'epoch': 1.55}\n",
            "{'loss': 2.5127, 'learning_rate': 2.3804474069585418e-05, 'epoch': 1.57}\n",
            "{'loss': 2.5017, 'learning_rate': 2.3488865323435844e-05, 'epoch': 1.59}\n",
            "{'loss': 2.4383, 'learning_rate': 2.317325657728627e-05, 'epoch': 1.61}\n",
            "{'loss': 2.4209, 'learning_rate': 2.2857647831136698e-05, 'epoch': 1.63}\n",
            "{'loss': 2.3884, 'learning_rate': 2.2542039084987124e-05, 'epoch': 1.65}\n",
            "{'loss': 2.4373, 'learning_rate': 2.222643033883755e-05, 'epoch': 1.67}\n",
            "{'loss': 2.4002, 'learning_rate': 2.191082159268798e-05, 'epoch': 1.69}\n",
            "{'loss': 2.442, 'learning_rate': 2.1595212846538404e-05, 'epoch': 1.7}\n",
            "{'loss': 2.3998, 'learning_rate': 2.127960410038883e-05, 'epoch': 1.72}\n",
            "{'loss': 2.4219, 'learning_rate': 2.096399535423926e-05, 'epoch': 1.74}\n",
            "{'loss': 2.4239, 'learning_rate': 2.0648386608089685e-05, 'epoch': 1.76}\n",
            "{'loss': 2.3798, 'learning_rate': 2.033277786194011e-05, 'epoch': 1.78}\n",
            "{'loss': 2.4434, 'learning_rate': 2.0017169115790536e-05, 'epoch': 1.8}\n",
            "{'loss': 2.3545, 'learning_rate': 1.9701560369640965e-05, 'epoch': 1.82}\n",
            "{'loss': 2.3995, 'learning_rate': 1.938595162349139e-05, 'epoch': 1.84}\n",
            "{'loss': 2.3337, 'learning_rate': 1.9070342877341817e-05, 'epoch': 1.86}\n",
            "{'loss': 2.4185, 'learning_rate': 1.8754734131192246e-05, 'epoch': 1.87}\n",
            "{'loss': 2.3841, 'learning_rate': 1.843912538504267e-05, 'epoch': 1.89}\n",
            "{'loss': 2.4064, 'learning_rate': 1.8123516638893097e-05, 'epoch': 1.91}\n",
            "{'loss': 2.405, 'learning_rate': 1.7807907892743526e-05, 'epoch': 1.93}\n",
            "{'loss': 2.3827, 'learning_rate': 1.749229914659395e-05, 'epoch': 1.95}\n",
            "{'loss': 2.3503, 'learning_rate': 1.7176690400444377e-05, 'epoch': 1.97}\n",
            "{'loss': 2.3746, 'learning_rate': 1.6861081654294806e-05, 'epoch': 1.99}\n",
            " 67% 52808/79212 [3:24:23<2:32:00,  2.90it/s]Metric: CompileTime\n",
            "  TotalSamples: 9\n",
            "  Accumulator: 03m01s134ms287.102us\n",
            "  ValueRate: 024ms799.725us / second\n",
            "  Rate: 0.00118253 / second\n",
            "  Percentiles: 1%=03s237ms464.652us; 5%=03s237ms464.652us; 10%=03s237ms464.652us; 20%=11s266ms557.661us; 50%=26s983ms791.619us; 80%=28s577ms125.419us; 90%=28s709ms447.415us; 95%=28s709ms447.415us; 99%=28s709ms447.415us\n",
            "Metric: DeviceLockWait\n",
            "  TotalSamples: 52881\n",
            "  Accumulator: 368ms439.786us\n",
            "  ValueRate: 172.927us / second\n",
            "  Rate: 2.76271 / second\n",
            "  Percentiles: 1%=003.123us; 5%=003.274us; 10%=003.357us; 20%=003.492us; 50%=003.746us; 80%=004.153us; 90%=004.369us; 95%=004.670us; 99%=005.150us\n",
            "Metric: ExecuteTime\n",
            "  TotalSamples: 32876\n",
            "  Accumulator: 03h32m28s255ms222.269us\n",
            "  ValueRate: 769ms111.706us / second\n",
            "  Rate: 2.76185 / second\n",
            "  Percentiles: 1%=277ms792.614us; 5%=277ms386.663us; 10%=278ms772.786us; 20%=278ms301.812us; 50%=279ms154.116us; 80%=280ms734.033us; 90%=280ms044.617us; 95%=280ms278.556us; 99%=281ms671.887us\n",
            "Metric: InboundData\n",
            "  TotalSamples: 67\n",
            "  Accumulator: 1.46GB\n",
            "  ValueRate: 130.51KB / second\n",
            "  Rate: 0.00571241 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=4.00B; 80%=4.00B; 90%=4.00B; 95%=4.00B; 99%=996.47MB\n",
            "Metric: InputOutputAliasCount\n",
            "  TotalSamples: 9\n",
            "  Accumulator: 4883.00\n",
            "  ValueRate: 0.64 / second\n",
            "  Rate: 0.00118388 / second\n",
            "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=203.00; 50%=813.00; 80%=813.00; 90%=817.00; 95%=817.00; 99%=817.00\n",
            "Metric: IrValueTensorToXlaData\n",
            "  TotalSamples: 816\n",
            "  Accumulator: 23s461ms870.425us\n",
            "  ValueRate: 373ms499.055us / second\n",
            "  Rate: 12.9908 / second\n",
            "  Percentiles: 1%=941.273us; 5%=001ms061.167us; 10%=001ms224.279us; 20%=002ms546.383us; 50%=002ms957.281us; 80%=028ms434.653us; 90%=097ms159.723us; 95%=100ms777.049us; 99%=104ms508.279us\n",
            "Metric: OutboundData\n",
            "  TotalSamples: 79647\n",
            "  Accumulator: 9.37GB\n",
            "  ValueRate: 346.20KB / second\n",
            "  Rate: 6.19366 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=8.00B; 80%=8.00B; 90%=512.00KB; 95%=512.00KB; 99%=512.00KB\n",
            "Metric: ReleaseDataHandlesTime\n",
            "  TotalSamples: 341714\n",
            "  Accumulator: 10m40s529ms765.517us\n",
            "  ValueRate: 050ms796.699us / second\n",
            "  Rate: 28.5689 / second\n",
            "  Percentiles: 1%=856.978us; 5%=001ms016.909us; 10%=001ms108.130us; 20%=001ms252.204us; 50%=002ms702.839us; 80%=002ms168.780us; 90%=002ms388.166us; 95%=003ms691.464us; 99%=003ms289.865us\n",
            "Metric: TensorsGraphSize\n",
            "  TotalSamples: 32876\n",
            "  Accumulator: 376931119.00\n",
            "  ValueRate: 31648.81 / second\n",
            "  Rate: 2.76022 / second\n",
            "  Percentiles: 1%=11484.00; 5%=11484.00; 10%=11484.00; 20%=11484.00; 50%=11484.00; 80%=11484.00; 90%=11484.00; 95%=11484.00; 99%=11484.00\n",
            "Metric: TransferFromServerTime\n",
            "  TotalSamples: 67\n",
            "  Accumulator: 07s251ms557.564us\n",
            "  ValueRate: 618.181us / second\n",
            "  Rate: 0.00571241 / second\n",
            "  Percentiles: 1%=002ms688.172us; 5%=002ms753.569us; 10%=002ms861.379us; 20%=002ms984.217us; 50%=002ms233.797us; 80%=002ms448.556us; 90%=006ms969.928us; 95%=006ms210.757us; 99%=04s204ms896.339us\n",
            "Metric: TransferToServerTime\n",
            "  TotalSamples: 79647\n",
            "  Accumulator: 03h43m59s798ms500.025us\n",
            "  ValueRate: 809ms579.002us / second\n",
            "  Rate: 6.1859 / second\n",
            "  Percentiles: 1%=002ms774.511us; 5%=002ms969.295us; 10%=002ms052.004us; 20%=002ms201.592us; 50%=208ms131.953us; 80%=263ms066.954us; 90%=272ms133.728us; 95%=273ms442.710us; 99%=274ms311.166us\n",
            "Metric: TransferToServerTransformTime\n",
            "  TotalSamples: 79647\n",
            "  Accumulator: 23s417ms033.340us\n",
            "  ValueRate: 002ms526.069us / second\n",
            "  Rate: 6.19366 / second\n",
            "  Percentiles: 1%=102.411us; 5%=124.373us; 10%=134.598us; 20%=144.892us; 50%=176.400us; 80%=228.724us; 90%=628.693us; 95%=813.854us; 99%=995.030us\n",
            "Counter: CachedCompile\n",
            "  Value: 32867\n",
            "Counter: CreateCompileHandles\n",
            "  Value: 9\n",
            "Counter: CreateDataHandles\n",
            "  Value: 26951868\n",
            "Counter: CreateXlaTensor\n",
            "  Value: 112515054\n",
            "Counter: DestroyDataHandles\n",
            "  Value: 26950204\n",
            "Counter: DestroyXlaTensor\n",
            "  Value: 112514030\n",
            "Counter: DeviceDataCacheMiss\n",
            "  Value: 32820\n",
            "Counter: MarkStep\n",
            "  Value: 52812\n",
            "Counter: ReleaseDataHandles\n",
            "  Value: 26950716\n",
            "Counter: UncachedCompile\n",
            "  Value: 9\n",
            "Counter: XRTAllocateFromTensor_Empty\n",
            "  Value: 450\n",
            "Counter: XrtCompile_Empty\n",
            "  Value: 144\n",
            "Counter: XrtExecuteChained_Empty\n",
            "  Value: 144\n",
            "Counter: XrtExecute_Empty\n",
            "  Value: 144\n",
            "Counter: XrtMemoryInfo_Empty\n",
            "  Value: 144\n",
            "Counter: XrtRead_Empty\n",
            "  Value: 723\n",
            "Counter: XrtReleaseAllocationHandle_Empty\n",
            "  Value: 144\n",
            "Counter: XrtReleaseCompileHandle_Empty\n",
            "  Value: 144\n",
            "Counter: XrtSessionCount\n",
            "  Value: 11\n",
            "Counter: XrtSubTuple_Empty\n",
            "  Value: 144\n",
            "Counter: aten::_local_scalar_dense\n",
            "  Value: 65\n",
            "Counter: xla::_copy_from\n",
            "  Value: 99241\n",
            "Counter: xla::_log_softmax\n",
            "  Value: 32808\n",
            "Counter: xla::_log_softmax_backward_data\n",
            "  Value: 32808\n",
            "Counter: xla::_s_where\n",
            "  Value: 32808\n",
            "Counter: xla::_softmax\n",
            "  Value: 393696\n",
            "Counter: xla::_softmax_backward_data\n",
            "  Value: 393696\n",
            "Counter: xla::_unsafe_view\n",
            "  Value: 3215184\n",
            "Counter: xla::add\n",
            "  Value: 2821488\n",
            "Counter: xla::add_\n",
            "  Value: 22473277\n",
            "Counter: xla::addcdiv_\n",
            "  Value: 6660024\n",
            "Counter: xla::addcmul\n",
            "  Value: 853008\n",
            "Counter: xla::addcmul_\n",
            "  Value: 6660024\n",
            "Counter: xla::as_strided\n",
            "  Value: 66433\n",
            "Counter: xla::bernoulli_\n",
            "  Value: 1213896\n",
            "Counter: xla::bmm\n",
            "  Value: 2362176\n",
            "Counter: xla::div\n",
            "  Value: 820200\n",
            "Counter: xla::div_\n",
            "  Value: 1213896\n",
            "Counter: xla::embedding\n",
            "  Value: 98424\n",
            "Counter: xla::embedding_dense_backward\n",
            "  Value: 98424\n",
            "Counter: xla::empty\n",
            "  Value: 1345945\n",
            "Counter: xla::empty_strided\n",
            "  Value: 66433\n",
            "Counter: xla::expand\n",
            "  Value: 1574784\n",
            "Counter: xla::fill_\n",
            "  Value: 32808\n",
            "Counter: xla::gelu\n",
            "  Value: 426504\n",
            "Counter: xla::gelu_backward\n",
            "  Value: 426504\n",
            "Counter: xla::index_select\n",
            "  Value: 98424\n",
            "Counter: xla::lt\n",
            "  Value: 32808\n",
            "Counter: xla::mm\n",
            "  Value: 7283376\n",
            "Counter: xla::mul\n",
            "  Value: 5872632\n",
            "Counter: xla::mul_\n",
            "  Value: 19980072\n",
            "Counter: xla::native_batch_norm\n",
            "  Value: 853008\n",
            "Counter: xla::native_batch_norm_backward\n",
            "  Value: 853008\n",
            "Counter: xla::nll_loss_backward\n",
            "  Value: 32808\n",
            "Counter: xla::nll_loss_forward\n",
            "  Value: 32808\n",
            "Counter: xla::norm\n",
            "  Value: 6692832\n",
            "Counter: xla::permute\n",
            "  Value: 3149568\n",
            "Counter: xla::rsub\n",
            "  Value: 32808\n",
            "Counter: xla::slice\n",
            "  Value: 98424\n",
            "Counter: xla::sqrt\n",
            "  Value: 6660024\n",
            "Counter: xla::stack\n",
            "  Value: 32808\n",
            "Counter: xla::sub_\n",
            "  Value: 65\n",
            "Counter: xla::sum\n",
            "  Value: 4166614\n",
            "Counter: xla::t\n",
            "  Value: 9711168\n",
            "Counter: xla::transpose\n",
            "  Value: 2362176\n",
            "Counter: xla::unsqueeze\n",
            "  Value: 65616\n",
            "Counter: xla::view\n",
            "  Value: 27132216\n",
            "Counter: xla::zero_\n",
            "  Value: 6660024\n",
            "Metric: XrtAllocateFromTensor\n",
            "  TotalSamples: 278082\n",
            "  Accumulator: 06m24s037ms275.590us\n",
            "  Mean: 001ms148.650us\n",
            "  StdDev: 493.522us\n",
            "  Rate: 16.1618 / second\n",
            "  Percentiles: 25%=683.064us; 50%=001ms160.943us; 80%=002ms580.977us; 90%=002ms818.215us; 95%=002ms970.086us; 99%=002ms294.089us\n",
            "Metric: XrtCompile\n",
            "  TotalSamples: 9\n",
            "  Accumulator: 03m01s593ms369.434us\n",
            "  Mean: 20s066ms929.937us\n",
            "  StdDev: 08s487ms606.283us\n",
            "  Rate: 0.00118253 / second\n",
            "  Percentiles: 25%=12s882ms857.353us; 50%=26s920ms112.839us; 80%=28s501ms011.701us; 90%=28s635ms667.540us; 95%=28s635ms667.540us; 99%=28s635ms667.540us\n",
            "Metric: XrtExecute\n",
            "  TotalSamples: 32876\n",
            "  Accumulator: 03h31m53s436ms923.762us\n",
            "  Mean: 275ms481.379us\n",
            "  StdDev: 011ms555.513us\n",
            "  Rate: 2.76185 / second\n",
            "  Percentiles: 25%=276ms542.523us; 50%=276ms203.636us; 80%=277ms722.510us; 90%=277ms962.516us; 95%=277ms153.536us; 99%=278ms585.830us\n",
            "Metric: XrtExecutorEvict\n",
            "  TotalSamples: 0\n",
            "  Accumulator: nanB\n",
            "  Mean: nanB\n",
            "  StdDev: nanB\n",
            "  Percentiles: \n",
            "Metric: XrtReadLiteral\n",
            "  TotalSamples: 676\n",
            "  Accumulator: 57s623ms860.291us\n",
            "  Mean: 084ms761.628us\n",
            "  StdDev: 089ms108.581us\n",
            "  Rate: 0.0576353 / second\n",
            "  Percentiles: 25%=014ms043.333us; 50%=057ms023.266us; 80%=153ms219.856us; 90%=211ms675.789us; 95%=267ms780.750us; 99%=381ms418.818us\n",
            "Metric: XrtReleaseAllocation\n",
            "  TotalSamples: 341715\n",
            "  Accumulator: 04m34s276ms902.263us\n",
            "  Mean: 676.496us\n",
            "  StdDev: 511.487us\n",
            "  Rate: 28.5684 / second\n",
            "  Percentiles: 25%=227.679us; 50%=622.746us; 80%=001ms062.892us; 90%=001ms327.525us; 95%=002ms574.241us; 99%=002ms257.834us\n",
            "\n",
            "{'loss': 2.3016, 'learning_rate': 1.6545472908145232e-05, 'epoch': 2.01}\n",
            "{'loss': 2.2835, 'learning_rate': 1.6229864161995658e-05, 'epoch': 2.03}\n",
            "{'loss': 2.2583, 'learning_rate': 1.5914255415846087e-05, 'epoch': 2.05}\n",
            "{'loss': 2.219, 'learning_rate': 1.5598646669696512e-05, 'epoch': 2.06}\n",
            "{'loss': 2.2697, 'learning_rate': 1.5283037923546938e-05, 'epoch': 2.08}\n",
            "{'loss': 2.2778, 'learning_rate': 1.4967429177397366e-05, 'epoch': 2.1}\n",
            "{'loss': 2.3217, 'learning_rate': 1.4651820431247793e-05, 'epoch': 2.12}\n",
            "{'loss': 2.28, 'learning_rate': 1.4336211685098219e-05, 'epoch': 2.14}\n",
            "{'loss': 2.3378, 'learning_rate': 1.4020602938948646e-05, 'epoch': 2.16}\n",
            "{'loss': 2.2416, 'learning_rate': 1.3704994192799073e-05, 'epoch': 2.18}\n",
            "{'loss': 2.262, 'learning_rate': 1.3389385446649499e-05, 'epoch': 2.2}\n",
            "{'loss': 2.2849, 'learning_rate': 1.3073776700499926e-05, 'epoch': 2.22}\n",
            "{'loss': 2.1909, 'learning_rate': 1.2758167954350354e-05, 'epoch': 2.23}\n",
            "{'loss': 2.2747, 'learning_rate': 1.2442559208200778e-05, 'epoch': 2.25}\n",
            "{'loss': 2.2287, 'learning_rate': 1.2126950462051205e-05, 'epoch': 2.27}\n",
            " 76% 60000/79212 [4:07:53<1:58:01,  2.71it/s][INFO|trainer.py:1637] 2021-04-12 09:31:48,148 >> Saving model checkpoint to /content/drive/MyDrive/goemo-mlm/checkpoint-60000\n",
            "[INFO|configuration_utils.py:329] 2021-04-12 09:31:48,166 >> Configuration saved in /content/drive/MyDrive/goemo-mlm/checkpoint-60000/config.json\n",
            "[INFO|modeling_utils.py:848] 2021-04-12 09:31:53,860 >> Model weights saved in /content/drive/MyDrive/goemo-mlm/checkpoint-60000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1907] 2021-04-12 09:31:53,867 >> tokenizer config file saved in /content/drive/MyDrive/goemo-mlm/checkpoint-60000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1913] 2021-04-12 09:31:53,872 >> Special tokens file saved in /content/drive/MyDrive/goemo-mlm/checkpoint-60000/special_tokens_map.json\n",
            "{'loss': 2.2711, 'learning_rate': 1.1811341715901632e-05, 'epoch': 2.29}\n",
            "{'loss': 2.2667, 'learning_rate': 1.1495732969752058e-05, 'epoch': 2.31}\n",
            "{'loss': 2.2313, 'learning_rate': 1.1180124223602485e-05, 'epoch': 2.33}\n",
            "{'loss': 2.2621, 'learning_rate': 1.0864515477452913e-05, 'epoch': 2.35}\n",
            "{'loss': 2.2733, 'learning_rate': 1.0548906731303338e-05, 'epoch': 2.37}\n",
            "{'loss': 2.2163, 'learning_rate': 1.0233297985153766e-05, 'epoch': 2.39}\n",
            "{'loss': 2.1929, 'learning_rate': 9.917689239004192e-06, 'epoch': 2.4}\n",
            "{'loss': 2.1896, 'learning_rate': 9.602080492854619e-06, 'epoch': 2.42}\n",
            "{'loss': 2.2179, 'learning_rate': 9.286471746705046e-06, 'epoch': 2.44}\n",
            "{'loss': 2.1703, 'learning_rate': 8.970863000555472e-06, 'epoch': 2.46}\n",
            "{'loss': 2.2579, 'learning_rate': 8.655254254405898e-06, 'epoch': 2.48}\n",
            "{'loss': 2.1966, 'learning_rate': 8.339645508256325e-06, 'epoch': 2.5}\n",
            "{'loss': 2.2079, 'learning_rate': 8.02403676210675e-06, 'epoch': 2.52}\n",
            "{'loss': 2.2423, 'learning_rate': 7.708428015957178e-06, 'epoch': 2.54}\n",
            "{'loss': 2.1994, 'learning_rate': 7.3928192698076045e-06, 'epoch': 2.56}\n",
            "{'loss': 2.2254, 'learning_rate': 7.077210523658032e-06, 'epoch': 2.58}\n",
            "{'loss': 2.1998, 'learning_rate': 6.761601777508458e-06, 'epoch': 2.59}\n",
            "{'loss': 2.2136, 'learning_rate': 6.445993031358885e-06, 'epoch': 2.61}\n",
            "{'loss': 2.2287, 'learning_rate': 6.1303842852093114e-06, 'epoch': 2.63}\n",
            "{'loss': 2.1859, 'learning_rate': 5.814775539059739e-06, 'epoch': 2.65}\n",
            "{'loss': 2.2079, 'learning_rate': 5.499166792910165e-06, 'epoch': 2.67}\n",
            "{'loss': 2.1951, 'learning_rate': 5.183558046760592e-06, 'epoch': 2.69}\n",
            "{'loss': 2.1796, 'learning_rate': 4.867949300611019e-06, 'epoch': 2.71}\n",
            "{'loss': 2.1328, 'learning_rate': 4.552340554461446e-06, 'epoch': 2.73}\n",
            "{'loss': 2.1661, 'learning_rate': 4.236731808311872e-06, 'epoch': 2.75}\n",
            "{'loss': 2.1865, 'learning_rate': 3.921123062162299e-06, 'epoch': 2.76}\n",
            "{'loss': 2.1681, 'learning_rate': 3.6055143160127257e-06, 'epoch': 2.78}\n",
            "{'loss': 2.1477, 'learning_rate': 3.289905569863152e-06, 'epoch': 2.8}\n",
            "{'loss': 2.1252, 'learning_rate': 2.974296823713579e-06, 'epoch': 2.82}\n",
            "{'loss': 2.1992, 'learning_rate': 2.6586880775640057e-06, 'epoch': 2.84}\n",
            "{'loss': 2.1204, 'learning_rate': 2.343079331414432e-06, 'epoch': 2.86}\n",
            "{'loss': 2.1446, 'learning_rate': 2.0274705852648587e-06, 'epoch': 2.88}\n",
            "{'loss': 2.1953, 'learning_rate': 1.7118618391152857e-06, 'epoch': 2.9}\n",
            "{'loss': 2.1783, 'learning_rate': 1.3962530929657124e-06, 'epoch': 2.92}\n",
            "{'loss': 2.1773, 'learning_rate': 1.0806443468161391e-06, 'epoch': 2.94}\n",
            "{'loss': 2.1157, 'learning_rate': 7.650356006665656e-07, 'epoch': 2.95}\n",
            "{'loss': 2.1208, 'learning_rate': 4.4942685451699243e-07, 'epoch': 2.97}\n",
            "{'loss': 2.1725, 'learning_rate': 1.3381810836741908e-07, 'epoch': 2.99}\n",
            "100% 79212/79212 [6:04:14<00:00,  2.88it/s]Metric: CompileTime\n",
            "  TotalSamples: 9\n",
            "  Accumulator: 03m01s134ms287.102us\n",
            "  ValueRate: 024ms799.725us / second\n",
            "  Rate: 0.00118253 / second\n",
            "  Percentiles: 1%=03s237ms464.652us; 5%=03s237ms464.652us; 10%=03s237ms464.652us; 20%=11s266ms557.661us; 50%=26s983ms791.619us; 80%=28s577ms125.419us; 90%=28s709ms447.415us; 95%=28s709ms447.415us; 99%=28s709ms447.415us\n",
            "Metric: DeviceLockWait\n",
            "  TotalSamples: 79342\n",
            "  Accumulator: 471ms800.638us\n",
            "  ValueRate: 010.973us / second\n",
            "  Rate: 2.75921 / second\n",
            "  Percentiles: 1%=003.125us; 5%=003.246us; 10%=003.316us; 20%=003.426us; 50%=003.706us; 80%=004.018us; 90%=004.304us; 95%=004.549us; 99%=012.279us\n",
            "Metric: ExecuteTime\n",
            "  TotalSamples: 59334\n",
            "  Accumulator: 05h35m18s754ms944.666us\n",
            "  ValueRate: 769ms063.389us / second\n",
            "  Rate: 2.75919 / second\n",
            "  Percentiles: 1%=277ms978.819us; 5%=277ms448.070us; 10%=278ms888.964us; 20%=278ms370.846us; 50%=279ms204.525us; 80%=280ms796.135us; 90%=280ms053.344us; 95%=280ms262.830us; 99%=281ms822.818us\n",
            "Metric: InboundData\n",
            "  TotalSamples: 122\n",
            "  Accumulator: 2.92GB\n",
            "  ValueRate: 143.36KB / second\n",
            "  Rate: 0.00571307 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=4.00B; 80%=4.00B; 90%=4.00B; 95%=4.00B; 99%=996.47MB\n",
            "Metric: InputOutputAliasCount\n",
            "  TotalSamples: 9\n",
            "  Accumulator: 4883.00\n",
            "  ValueRate: 0.64 / second\n",
            "  Rate: 0.00118388 / second\n",
            "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=203.00; 50%=813.00; 80%=813.00; 90%=817.00; 95%=817.00; 99%=817.00\n",
            "Metric: IrValueTensorToXlaData\n",
            "  TotalSamples: 816\n",
            "  Accumulator: 23s461ms870.425us\n",
            "  ValueRate: 373ms499.055us / second\n",
            "  Rate: 12.9908 / second\n",
            "  Percentiles: 1%=941.273us; 5%=001ms061.167us; 10%=001ms224.279us; 20%=002ms546.383us; 50%=002ms957.281us; 80%=028ms434.653us; 90%=097ms159.723us; 95%=100ms777.049us; 99%=104ms508.279us\n",
            "Metric: OutboundData\n",
            "  TotalSamples: 139056\n",
            "  Accumulator: 12.59GB\n",
            "  ValueRate: 346.84KB / second\n",
            "  Rate: 6.20504 / second\n",
            "  Percentiles: 1%=4.00B; 5%=4.00B; 10%=4.00B; 20%=4.00B; 50%=8.00B; 80%=8.00B; 90%=512.00KB; 95%=512.00KB; 99%=512.00KB\n",
            "Metric: ReleaseDataHandlesTime\n",
            "  TotalSamples: 609159\n",
            "  Accumulator: 17m26s334ms816.189us\n",
            "  ValueRate: 049ms115.702us / second\n",
            "  Rate: 27.8748 / second\n",
            "  Percentiles: 1%=857.417us; 5%=001ms037.567us; 10%=001ms113.073us; 20%=001ms258.193us; 50%=002ms718.878us; 80%=002ms150.505us; 90%=002ms414.053us; 95%=003ms652.324us; 99%=004ms647.437us\n",
            "Metric: TensorsGraphSize\n",
            "  TotalSamples: 59334\n",
            "  Accumulator: 680275907.00\n",
            "  ValueRate: 31637.19 / second\n",
            "  Rate: 2.75921 / second\n",
            "  Percentiles: 1%=11484.00; 5%=11484.00; 10%=11484.00; 20%=11484.00; 50%=11484.00; 80%=11484.00; 90%=11484.00; 95%=11484.00; 99%=11484.00\n",
            "Metric: TransferFromServerTime\n",
            "  TotalSamples: 122\n",
            "  Accumulator: 15s268ms425.997us\n",
            "  ValueRate: 714.997us / second\n",
            "  Rate: 0.00571307 / second\n",
            "  Percentiles: 1%=002ms686.364us; 5%=002ms753.569us; 10%=002ms869.890us; 20%=002ms969.033us; 50%=002ms165.713us; 80%=002ms385.816us; 90%=005ms031.369us; 95%=006ms189.159us; 99%=04s204ms896.339us\n",
            "Metric: TransferToServerTime\n",
            "  TotalSamples: 139056\n",
            "  Accumulator: 05h53m01s734ms077.332us\n",
            "  ValueRate: 809ms083.490us / second\n",
            "  Rate: 6.19723 / second\n",
            "  Percentiles: 1%=002ms844.491us; 5%=002ms989.818us; 10%=002ms088.009us; 20%=002ms220.860us; 50%=209ms599.887us; 80%=263ms845.811us; 90%=273ms628.036us; 95%=274ms767.625us; 99%=274ms466.582us\n",
            "Metric: TransferToServerTransformTime\n",
            "  TotalSamples: 139056\n",
            "  Accumulator: 38s934ms372.429us\n",
            "  ValueRate: 002ms560.719us / second\n",
            "  Rate: 6.20504 / second\n",
            "  Percentiles: 1%=101.592us; 5%=119.973us; 10%=130.323us; 20%=145.010us; 50%=182.901us; 80%=231.887us; 90%=644.968us; 95%=833.606us; 99%=994.877us\n",
            "Counter: CachedCompile\n",
            "  Value: 59325\n",
            "Counter: CreateCompileHandles\n",
            "  Value: 9\n",
            "Counter: CreateDataHandles\n",
            "  Value: 48575984\n",
            "Counter: CreateXlaTensor\n",
            "  Value: 203001561\n",
            "Counter: DestroyDataHandles\n",
            "  Value: 48574831\n",
            "Counter: DestroyXlaTensor\n",
            "  Value: 203000537\n",
            "Counter: DeviceDataCacheMiss\n",
            "  Value: 59224\n",
            "Counter: MarkStep\n",
            "  Value: 79216\n",
            "Counter: ReleaseDataHandles\n",
            "  Value: 48574831\n",
            "Counter: UncachedCompile\n",
            "  Value: 9\n",
            "Counter: XRTAllocateFromTensor_Empty\n",
            "  Value: 450\n",
            "Counter: XrtCompile_Empty\n",
            "  Value: 144\n",
            "Counter: XrtExecuteChained_Empty\n",
            "  Value: 144\n",
            "Counter: XrtExecute_Empty\n",
            "  Value: 144\n",
            "Counter: XrtMemoryInfo_Empty\n",
            "  Value: 144\n",
            "Counter: XrtRead_Empty\n",
            "  Value: 1113\n",
            "Counter: XrtReleaseAllocationHandle_Empty\n",
            "  Value: 144\n",
            "Counter: XrtReleaseCompileHandle_Empty\n",
            "  Value: 144\n",
            "Counter: XrtSessionCount\n",
            "  Value: 11\n",
            "Counter: XrtSubTuple_Empty\n",
            "  Value: 144\n",
            "Counter: aten::_local_scalar_dense\n",
            "  Value: 118\n",
            "Counter: xla::_copy_from\n",
            "  Value: 178453\n",
            "Counter: xla::_log_softmax\n",
            "  Value: 59212\n",
            "Counter: xla::_log_softmax_backward_data\n",
            "  Value: 59212\n",
            "Counter: xla::_s_where\n",
            "  Value: 59212\n",
            "Counter: xla::_softmax\n",
            "  Value: 710544\n",
            "Counter: xla::_softmax_backward_data\n",
            "  Value: 710544\n",
            "Counter: xla::_unsafe_view\n",
            "  Value: 5802776\n",
            "Counter: xla::add\n",
            "  Value: 5092232\n",
            "Counter: xla::add_\n",
            "  Value: 40560017\n",
            "Counter: xla::addcdiv_\n",
            "  Value: 12020036\n",
            "Counter: xla::addcmul\n",
            "  Value: 1539512\n",
            "Counter: xla::addcmul_\n",
            "  Value: 12020036\n",
            "Counter: xla::as_strided\n",
            "  Value: 119241\n",
            "Counter: xla::bernoulli_\n",
            "  Value: 2190844\n",
            "Counter: xla::bmm\n",
            "  Value: 4263264\n",
            "Counter: xla::div\n",
            "  Value: 1480300\n",
            "Counter: xla::div_\n",
            "  Value: 2190844\n",
            "Counter: xla::embedding\n",
            "  Value: 177636\n",
            "Counter: xla::embedding_dense_backward\n",
            "  Value: 177636\n",
            "Counter: xla::empty\n",
            "  Value: 2428509\n",
            "Counter: xla::empty_strided\n",
            "  Value: 119241\n",
            "Counter: xla::expand\n",
            "  Value: 2842176\n",
            "Counter: xla::fill_\n",
            "  Value: 59212\n",
            "Counter: xla::gelu\n",
            "  Value: 769756\n",
            "Counter: xla::gelu_backward\n",
            "  Value: 769756\n",
            "Counter: xla::index_select\n",
            "  Value: 177636\n",
            "Counter: xla::lt\n",
            "  Value: 59212\n",
            "Counter: xla::mm\n",
            "  Value: 13145064\n",
            "Counter: xla::mul\n",
            "  Value: 10598948\n",
            "Counter: xla::mul_\n",
            "  Value: 36060108\n",
            "Counter: xla::native_batch_norm\n",
            "  Value: 1539512\n",
            "Counter: xla::native_batch_norm_backward\n",
            "  Value: 1539512\n",
            "Counter: xla::nll_loss_backward\n",
            "  Value: 59212\n",
            "Counter: xla::nll_loss_forward\n",
            "  Value: 59212\n",
            "Counter: xla::norm\n",
            "  Value: 12079248\n",
            "Counter: xla::permute\n",
            "  Value: 5684352\n",
            "Counter: xla::rsub\n",
            "  Value: 59212\n",
            "Counter: xla::slice\n",
            "  Value: 177636\n",
            "Counter: xla::sqrt\n",
            "  Value: 12020036\n",
            "Counter: xla::stack\n",
            "  Value: 59212\n",
            "Counter: xla::sub_\n",
            "  Value: 118\n",
            "Counter: xla::sum\n",
            "  Value: 7519921\n",
            "Counter: xla::t\n",
            "  Value: 17526752\n",
            "Counter: xla::transpose\n",
            "  Value: 4263264\n",
            "Counter: xla::unsqueeze\n",
            "  Value: 118424\n",
            "Counter: xla::view\n",
            "  Value: 48968324\n",
            "Counter: xla::zero_\n",
            "  Value: 12020036\n",
            "Metric: XrtAllocateFromTensor\n",
            "  TotalSamples: 436506\n",
            "  Accumulator: 10m33s022ms754.886us\n",
            "  Mean: 001ms156.972us\n",
            "  StdDev: 528.024us\n",
            "  Rate: 16.1082 / second\n",
            "  Percentiles: 25%=644.658us; 50%=001ms180.433us; 80%=002ms672.216us; 90%=002ms847.934us; 95%=002ms979.771us; 99%=002ms298.381us\n",
            "Metric: XrtCompile\n",
            "  TotalSamples: 9\n",
            "  Accumulator: 03m01s593ms369.434us\n",
            "  Mean: 20s066ms929.937us\n",
            "  StdDev: 08s487ms606.283us\n",
            "  Rate: 0.00118253 / second\n",
            "  Percentiles: 25%=12s882ms857.353us; 50%=26s920ms112.839us; 80%=28s501ms011.701us; 90%=28s635ms667.540us; 95%=28s635ms667.540us; 99%=28s635ms667.540us\n",
            "Metric: XrtExecute\n",
            "  TotalSamples: 59334\n",
            "  Accumulator: 05h32m23s762ms006.712us\n",
            "  Mean: 276ms654.354us\n",
            "  StdDev: 008ms063.384us\n",
            "  Rate: 2.7592 / second\n",
            "  Percentiles: 25%=276ms538.979us; 50%=276ms145.827us; 80%=277ms635.933us; 90%=277ms878.097us; 95%=277ms038.719us; 99%=277ms497.911us\n",
            "Metric: XrtExecutorEvict\n",
            "  TotalSamples: 0\n",
            "  Accumulator: nanB\n",
            "  Mean: nanB\n",
            "  StdDev: nanB\n",
            "  Percentiles: \n",
            "Metric: XrtReadLiteral\n",
            "  TotalSamples: 1340\n",
            "  Accumulator: 02m55s208ms536.481us\n",
            "  Mean: 091ms058.561us\n",
            "  StdDev: 091ms256.101us\n",
            "  Rate: 0.0721964 / second\n",
            "  Percentiles: 25%=016ms906.025us; 50%=071ms635.283us; 80%=155ms615.998us; 90%=220ms290.641us; 95%=278ms256.983us; 99%=386ms349.974us\n",
            "Metric: XrtReleaseAllocation\n",
            "  TotalSamples: 609159\n",
            "  Accumulator: 07m31s081ms271.872us\n",
            "  Mean: 659.013us\n",
            "  StdDev: 479.681us\n",
            "  Rate: 27.8747 / second\n",
            "  Percentiles: 25%=234.416us; 50%=637.849us; 80%=001ms041.842us; 90%=001ms254.619us; 95%=002ms519.955us; 99%=002ms095.784us\n",
            "\n",
            "[INFO|trainer.py:1198] 2021-04-12 11:28:09,413 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 21854.4752, 'train_samples_per_second': 3.625, 'epoch': 3.0}\n",
            "100% 79212/79212 [6:04:14<00:00,  3.62it/s]\n",
            "[INFO|trainer.py:1637] 2021-04-12 11:28:18,256 >> Saving model checkpoint to /content/drive/MyDrive/goemo-mlm\n",
            "[INFO|configuration_utils.py:329] 2021-04-12 11:28:18,274 >> Configuration saved in /content/drive/MyDrive/goemo-mlm/config.json\n",
            "[INFO|modeling_utils.py:848] 2021-04-12 11:28:43,485 >> Model weights saved in /content/drive/MyDrive/goemo-mlm/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1907] 2021-04-12 11:28:43,492 >> tokenizer config file saved in /content/drive/MyDrive/goemo-mlm/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1913] 2021-04-12 11:28:43,497 >> Special tokens file saved in /content/drive/MyDrive/goemo-mlm/special_tokens_map.json\n",
            "[INFO|trainer_pt_utils.py:722] 2021-04-12 11:28:43,545 >> ***** train metrics *****\n",
            "[INFO|trainer_pt_utils.py:727] 2021-04-12 11:28:43,546 >>   epoch                      =        3.0\n",
            "[INFO|trainer_pt_utils.py:727] 2021-04-12 11:28:43,546 >>   init_mem_cpu_alloc_delta   =       -2MB\n",
            "[INFO|trainer_pt_utils.py:727] 2021-04-12 11:28:43,546 >>   init_mem_cpu_peaked_delta  =        4MB\n",
            "[INFO|trainer_pt_utils.py:727] 2021-04-12 11:28:43,546 >>   train_mem_cpu_alloc_delta  =     4294MB\n",
            "[INFO|trainer_pt_utils.py:727] 2021-04-12 11:28:43,546 >>   train_mem_cpu_peaked_delta =       10MB\n",
            "[INFO|trainer_pt_utils.py:727] 2021-04-12 11:28:43,546 >>   train_runtime              = 6:04:14.47\n",
            "[INFO|trainer_pt_utils.py:727] 2021-04-12 11:28:43,546 >>   train_samples              =     211225\n",
            "[INFO|trainer_pt_utils.py:727] 2021-04-12 11:28:43,546 >>   train_samples_per_second   =      3.625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4vweArYUR3d"
      },
      "source": [
        "# 3b. Finetuning Go-Emotions Pre-Trained BERT on NUSWhispers\n",
        "\n",
        " *Remember to change runtime back to GPU*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qucqkELKTSfz"
      },
      "source": [
        "model_name = '/content/drive/MyDrive/goemo-mlm'\n",
        "num_labels = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB0-_EUlaVR7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167,
          "referenced_widgets": [
            "2a9f8d30e9d24c048cabea03bc43826d",
            "0d0c05e73732465dbe93c184e97c7f99",
            "5285810949334e998d2c353356e84591",
            "425851ff7ed845889176491dd06e5299",
            "18d472283f4a426889b9eb5417d5829b",
            "903cda2959ce4f78b09452cdc27e63ab",
            "bdf97b9602604694a38002d63aac1056",
            "a0018aec64404723b365555933d4d87c",
            "32b0deb027024c95bea8f4be5ebf81c2",
            "42b4336ee8354ef880fa907bd116bc14",
            "dfc419c7e57c4a5787f259bdf428b962",
            "392c2971927745e4844de553b54c972d",
            "1e02eacf2ab74e95aa0a4082bd71acd8",
            "953aded622674c5c9dfc9c0c4e6aeab9",
            "f2b88817807145af81dcac32b63661f7",
            "e754a62e09f24f78a5c8ba5a7645efc3",
            "c845bd78fb674243b934a86c19747a3a",
            "545737ba2cbf42e082fa6828d1f51ce9",
            "e29508b35c304443bb1daa9b27c6a45f",
            "0be6057b0f244431a684a3afdefd8bd0",
            "c253fbc338e74229aa37163354701387",
            "bbf0e481650048be9cd8d688cd20340b",
            "a50fb00ee0194fe2a10a7f85208196f5",
            "9ba3e0c082674f89a15b26b824c820d9"
          ]
        },
        "outputId": "df4d478b-53c2-4a31-dc87-86677463c2b5"
      },
      "source": [
        "# Train up Goemo bert on NUSwhspers\n",
        "# load NUSWhispers dataset\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizerFast\n",
        "from datasets import Dataset, load_metric\n",
        "\n",
        "data_file = '/content/CS4248-Team23/data/v6_remove_punctuation_remove_non_english_correct_spelling_replace_short_form_slang.csv'\n",
        "\n",
        "old_train = pd.read_csv(data_file)\n",
        "train = deepcopy(old_train)\n",
        "\n",
        "train_dataset, test_dataset = train_test_split(train, test_size=0.2, random_state=10)\n",
        "train_dataset, val_dataset = train_test_split(train, test_size=0.2, random_state=10)\n",
        "test_dataset, val_dataset = train_test_split(val_dataset, test_size=0.5, random_state=10)\n",
        "\n",
        "train_dataset_text = deepcopy(train_dataset[['text','label']])\n",
        "val_dataset_text = deepcopy(val_dataset[['text','label']])\n",
        "test_dataset_text = deepcopy(test_dataset[['text','label']])\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_dataset_text)\n",
        "val_dataset = Dataset.from_pandas(val_dataset_text)\n",
        "test_dataset = Dataset.from_pandas(test_dataset_text)\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
        "val_dataset = val_dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
        "\n",
        "columns_to_return = ['input_ids', 'label', 'attention_mask']\n",
        "train_dataset.set_format(type='torch', columns=columns_to_return)\n",
        "val_dataset.set_format(type='torch', columns=columns_to_return)\n",
        "test_dataset.set_format(type='torch', columns=columns_to_return)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a9f8d30e9d24c048cabea03bc43826d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32b0deb027024c95bea8f4be5ebf81c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c845bd78fb674243b934a86c19747a3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbnieT9NTMoj",
        "outputId": "b003a29f-e900-4796-c985-89ec1f5a2cd8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import GELU\n",
        "from transformers import BertModel, BertForSequenceClassification, BertForPreTraining,\\\n",
        "                         BertTokenizerFast, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def pt_bert(model_name, num_labels, train_mode=True):\n",
        "  model = BertForSequenceClassification.from_pretrained(model_name, \n",
        "                                                        num_labels=num_labels,)\n",
        "  if train_mode:\n",
        "    model.train()\n",
        "  return model\n",
        "\n",
        "model = pt_bert(model_name, num_labels, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/goemo-mlm were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/goemo-mlm and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SFD2u9HoTZ9u",
        "outputId": "dce0aac4-7dc8-4780-b46d-d73c9f8f47e2"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./genwbert/results',          # output directory\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=4.0,            # total # of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    warmup_ratio=0.1,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./genwbert/logs',            # directory for storing logs\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        ")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='1764' max='1764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1764/1764 25:14, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.277500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.943000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.667200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1764, training_loss=0.894660015495456, metrics={'train_runtime': 1515.9162, 'train_samples_per_second': 1.164, 'total_flos': 4691647640678400.0, 'epoch': 4.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 1060864, 'train_mem_gpu_alloc_delta': 911140864, 'train_mem_cpu_peaked_delta': 4096, 'train_mem_gpu_peaked_delta': 6556587520})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "0jW5rDDnTenG",
        "outputId": "64a9d443-a9ce-49e5-d4c5-7f54178075f1"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='168' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [56/56 21:30]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 4.0,\n",
              " 'eval_accuracy': 0.5374149659863946,\n",
              " 'eval_f1': 0.40829767690940344,\n",
              " 'eval_loss': 1.4052960872650146,\n",
              " 'eval_mem_cpu_alloc_delta': -40960,\n",
              " 'eval_mem_cpu_peaked_delta': 40960,\n",
              " 'eval_mem_gpu_alloc_delta': 0,\n",
              " 'eval_mem_gpu_peaked_delta': 390193152,\n",
              " 'eval_precision': 0.43933094384707294,\n",
              " 'eval_recall': 0.4113299109516214,\n",
              " 'eval_runtime': 8.3014,\n",
              " 'eval_samples_per_second': 53.123}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Qr75DSLSTlNs",
        "outputId": "e442f4b5-8776-4911-ddb2-69914e426652"
      },
      "source": [
        "import json \n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "print(predictions.metrics)\n",
        "\n",
        "with open('results.json', 'w+') as f:\n",
        "  f.write(json.dumps(predictions.metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='112' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [56/56 00:16]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'test_loss': 1.3832087516784668, 'test_accuracy': 0.5351473922902494, 'test_f1': 0.44770590825570683, 'test_precision': 0.5446675640695873, 'test_recall': 0.43751330519547305, 'test_runtime': 8.2763, 'test_samples_per_second': 53.285, 'test_mem_cpu_alloc_delta': -45056, 'test_mem_gpu_alloc_delta': 0, 'test_mem_cpu_peaked_delta': 45056, 'test_mem_gpu_peaked_delta': 390197760}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKf7kGP4TlNt"
      },
      "source": [
        "# save model\n",
        "save_directory = '/content/drive/MyDrive/ge_nw_bert/'\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDNlyneJTxhq"
      },
      "source": [
        "# 3c. Extracting Contextual Embeddings of Go-Emotions Pre-Trained & NUSWhispers Fine-Tuned BERT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu_vspCiTxhs"
      },
      "source": [
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "\n",
        "save_directory = '/content/drive/MyDrive/ge_nw_bert/'\n",
        "tokenizer = BertTokenizerFast.from_pretrained(save_directory)\n",
        "model = BertForSequenceClassification.from_pretrained(save_directory,\n",
        "                                                      output_hidden_states=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6LVRDzQTxhs"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "2b45aeb67e7e4481b3b0c0da507bc0d5",
            "e8e48d07059e455a9843819d4f475c56",
            "25f7b59f5a074718b830a8337595c9b6",
            "34082f50a641461698058384154e8b9f",
            "e63a8f7849b0435090452d2f61ed5c9f",
            "6ea034ec296b45d4acfb2e6ae7fb2130",
            "2d9accbe20f54075ba74c74425c92c96",
            "d284d76934cb4d0f994f69a1e2d89522"
          ]
        },
        "id": "_JRjtPuWTxht",
        "outputId": "69dcd6bb-fee5-4515-d00a-e5c2ca072548"
      },
      "source": [
        "# load NUSWhispers dataset\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, load_metric\n",
        "\n",
        "data_file = '/content/CS4248-Team23/data/v6_remove_punctuation_remove_non_english_correct_spelling_replace_short_form_slang.csv'\n",
        "\n",
        "old_train = pd.read_csv(data_file)\n",
        "train = deepcopy(old_train)\n",
        "\n",
        "train_dataset_text = deepcopy(train[['text','label']])\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_dataset_text)\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True, load_from_cache_file=False)\n",
        "\n",
        "columns_to_return = ['input_ids', 'label', 'attention_mask']\n",
        "train_dataset.set_format(type='torch', columns=columns_to_return)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b45aeb67e7e4481b3b0c0da507bc0d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPdjv6qmTxht"
      },
      "source": [
        "Here we are extracting the embeddings produced by the final hidden layer (before the classification head), where we simply used the embeddings of each post's [CLS] token (a special token appended to the start of every text by the BERT tokenizer). There are also other strategies, e.g. average or max pooling all token's embeddings, taking the 2nd to last hidden layer's embeddings instead of the last, or even pooling the last 4 hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S2XSZ_vTxht"
      },
      "source": [
        "def generate_embedding(x):\n",
        "  inputs = {\n",
        "    \"input_ids\": torch.tensor(x['input_ids']).unsqueeze(0),\n",
        "    \"attention_mask\": torch.tensor(x['attention_mask']).unsqueeze(0),\n",
        "  }\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output = model(**inputs)\n",
        "    logits = output[0]\n",
        "    hidden_states = output[1]\n",
        "    last_hidden_state = hidden_states[1] # layer right before the classification head\n",
        "  # Get [CLS] embedding\n",
        "  features = last_hidden_state[:,0,:].numpy()\n",
        "\n",
        "  return features\n",
        "\n",
        "df = train_dataset.to_pandas()\n",
        "embeddings = df.apply(generate_embedding, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6RVTO1gTxhu"
      },
      "source": [
        "# sanity check\n",
        "# b = generate_embedding(df.iloc[0])\n",
        "# c = generate_embedding(df.iloc[100])\n",
        "# c[1][1][:,0,:] - b[1][1][:,0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd5WX3wKTxhu",
        "outputId": "dbd9191b-70c2-4129-a4c6-fc598025a5a0"
      },
      "source": [
        "embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [[0.27817735, -0.08260021, -0.008533872, 0.228...\n",
              "1       [[0.22157842, -0.02904309, -0.03032327, 0.1960...\n",
              "2       [[0.2006335, 0.090700924, -0.10094186, 0.15031...\n",
              "3       [[0.2374434, 0.107041694, -0.122428514, 0.1505...\n",
              "4       [[0.18441899, 0.03906344, -0.064785875, 0.1099...\n",
              "                              ...                        \n",
              "4402    [[0.21776429, 0.049682744, -0.09176226, 0.1267...\n",
              "4403    [[0.23981403, 0.07714494, -0.111232854, 0.1523...\n",
              "4404    [[0.25274277, -0.037078705, -0.01557099, 0.189...\n",
              "4405    [[0.2536971, -0.06730342, -0.064660765, 0.1913...\n",
              "4406    [[0.27818578, -0.08658751, -0.022273915, 0.224...\n",
              "Length: 4407, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPUk4duCTxhu"
      },
      "source": [
        "embeddings.to_csv('drive/MyDrive/ge_nw_bert_embeddings.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7_MffubcCE9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}